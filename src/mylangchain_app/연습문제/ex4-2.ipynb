{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28f0a3e7",
   "metadata": {},
   "source": [
    "#### 문제 4-2 : 조건부 분기가 있는 메뉴 추천 시스템 ( LangGraph 사용)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e692391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])\n",
    "\n",
    "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "print(UPSTAGE_API_KEY[30:])\n",
    "\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "print(TAVILY_API_KEY[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ea6efad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "# LangGraph MessagesState라는 미리 만들어진 상태를 사용\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "from textwrap import dedent\n",
    "from typing import List, Literal, Tuple\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import uuid\n",
    "\n",
    "#from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eef2a515",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "\n",
    "# cafe_db 벡터 저장소 로드 (4-2는 카페 메뉴 전용)\n",
    "cafe_db = FAISS.load_local(\n",
    "    \"../db/cafe_db\", \n",
    "    embeddings_model, \n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "# Tool 정의 (조건부 분기 추가)\n",
    "from langchain.agents import tool\n",
    "import re\n",
    "\n",
    "@tool\n",
    "def search_cafe(query: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    카페 메뉴에서 정보를 검색합니다.\n",
    "    사용자 질문을 분류하여 (메뉴/가격/추천) 맞춤 검색을 실행합니다.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) 문의 유형 분류\n",
    "    q_lower = query.lower()\n",
    "    if \"가격\" in query or \"얼마\" in query:\n",
    "        query_type = \"price\"\n",
    "    elif \"추천\" in query or \"인기\" in query:\n",
    "        query_type = \"recommend\"\n",
    "    else:\n",
    "        query_type = \"menu\"\n",
    "\n",
    "    # 2) 유형별 검색 전략\n",
    "    if query_type == \"price\":\n",
    "        docs = cafe_db.similarity_search(\"카페 메뉴 가격\", k=5)\n",
    "    elif query_type == \"recommend\":\n",
    "        docs = cafe_db.similarity_search(query, k=3)\n",
    "        if not docs:\n",
    "            docs = cafe_db.similarity_search(\"인기 카페 메뉴\", k=3)\n",
    "    else:  # 일반 메뉴 문의\n",
    "        docs = cafe_db.similarity_search(query, k=4)\n",
    "\n",
    "    # 3) 결과 정리\n",
    "    if not docs:\n",
    "        return [\"관련 카페 메뉴 정보를 찾을 수 없습니다.\"]\n",
    "\n",
    "    formatted_docs = [\n",
    "        f'<Document source=\"{doc.metadata.get(\"source\",\"N/A\")}\">\\n{doc.page_content}\\n</Document>'\n",
    "        for doc in docs\n",
    "    ]\n",
    "    return formatted_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c944e5c",
   "metadata": {},
   "source": [
    "` LangChain 내장 도구`\n",
    "- 일반 웹 검색을 위한 Tavily 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "416704c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain 내장 Tavily 도구 (웹 검색)\n",
    "from langchain.agents import tool\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "@tool\n",
    "def search_web(query: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    카페 메뉴 DB(cafe_db)에 없는 정보나 최신 정보를 검색합니다.\n",
    "    예: '올해 가장 인기 있는 음료 트렌드', '카페 신메뉴 소식' 등\n",
    "    \"\"\"\n",
    "    # Tavily 검색 엔진 초기화\n",
    "    tavily_search = TavilySearchResults(max_results=3)\n",
    "    docs = tavily_search.invoke(query)\n",
    "\n",
    "    # 검색 결과 포맷팅\n",
    "    formatted_docs = \"\\n\\n---\\n\\n\".join(\n",
    "        [\n",
    "            f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if len(docs) > 0:\n",
    "        return formatted_docs\n",
    "    \n",
    "    return \"관련 최신 정보를 찾을 수 없습니다.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd083db",
   "metadata": {},
   "source": [
    "### bind_tools() 함수로 LLM과 Tool 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87033732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solar-pro\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM 모델 설정\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\", streaming=True)  # OpenAI 사용시\n",
    "llm = ChatUpstage(\n",
    "    model=\"solar-pro\",\n",
    "    base_url=\"https://api.upstage.ai/v1\",\n",
    "    temperature=0.5\n",
    ")\n",
    "print(llm.model_name)\n",
    "\n",
    "# 도구 목록 (카페 전용 DB 검색 + 웹 검색)\n",
    "tools = [search_cafe, search_web]\n",
    "\n",
    "# 모델에 도구를 바인딩 (RunnableBindings)\n",
    "llm_with_tools = llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffd13c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 도구 호출 테스트 ===\n",
    "\n",
    "# 1) 카페 메뉴 DB 검색 테스트\n",
    "tool_call = llm_with_tools.invoke(\n",
    "    [HumanMessage(content=\"아메리카노 가격은 얼마인가요?\")]\n",
    ")\n",
    "print(\"\\n[카페 메뉴 DB 호출 결과]\")\n",
    "pprint(tool_call.additional_kwargs)\n",
    "\n",
    "# 2) 웹 검색(Tavily) 테스트\n",
    "tool_call = llm_with_tools.invoke(\n",
    "    [HumanMessage(content=\"최근에 공개된 오픈소스 LLM 모델은 어떤 것들이 있나요?\")]\n",
    ")\n",
    "print(\"\\n[웹 검색 호출 결과]\")\n",
    "pprint(tool_call.additional_kwargs)\n",
    "\n",
    "# 3) 단순 연산 (도구 불필요) 테스트\n",
    "tool_call = llm_with_tools.invoke(\n",
    "    [HumanMessage(content=\"3+3은 얼마인가요?\")]\n",
    ")\n",
    "print(\"\\n[일반 질의 결과]\")\n",
    "pprint(tool_call.additional_kwargs)\n",
    "\n",
    "# 전체 응답 객체 확인 (마지막 호출 기준)\n",
    "print(\"\\n[최종 tool_call 객체]\")\n",
    "pprint(tool_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5c5de4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[카페 메뉴 질의 → LLM의 tool_calls]\n",
      "{'refusal': None,\n",
      " 'tool_calls': [{'function': {'arguments': '{\"query\": '\n",
      "                                           '\"\\\\uc544\\\\uba54\\\\ub9ac\\\\uce74\\\\ub178 '\n",
      "                                           '\\\\uac00\\\\uaca9\"}',\n",
      "                              'name': 'search_cafe'},\n",
      "                 'id': 'chatcmpl-tool-44bb2373ba9845d0a5fdb68c52d269cf',\n",
      "                 'type': 'function'}]}\n",
      "\n",
      "[ToolNode 실행 결과]\n",
      "<class 'langchain_core.messages.tool.ToolMessage'>\n",
      "[\"<Document source=\\\"../data/cafe_menu_data.txt\\\">\\n4. 바닐라 라떼\\n   • 가격: ₩6,000\\n   • 주요 원료: 에스프레소, 스팀 밀크, 바닐라 시럽\\n   • 설명: 카페라떼에 달콤한 바닐라 시럽을 더한 인기 메뉴입니다. 바닐라의 달콤함과 커피의 쌉싸름함이 조화롭게 어우러지며, 휘핑크림 토핑으로 더욱 풍성한 맛을 즐길 수 있습니다.\\n</Document>\", \"<Document source=\\\"../data/cafe_menu_data.txt\\\">\\n2. 카페라떼\\n   • 가격: ₩5,500\\n   • 주요 원료: 에스프레소, 스팀 밀크\\n   • 설명: 진한 에스프레소에 부드럽게 스팀한 우유를 넣어 만든 대표적인 밀크 커피입니다. 크리미한 질감과 부드러운 맛이 특징이며, 다양한 시럽과 토핑 추가가 가능합니다. 라떼 아트로 시각적 즐거움도 제공합니다.\\n</Document>\", \"<Document source=\\\"../data/cafe_menu_data.txt\\\">\\n3. 카푸치노\\n   • 가격: ₩5,000\\n   • 주요 원료: 에스프레소, 스팀 밀크, 우유 거품\\n   • 설명: 에스프레소, 스팀 밀크, 우유 거품이 1:1:1 비율로 구성된 이탈리아 전통 커피입니다. 진한 커피 맛과 부드러운 우유 거품의 조화가 일품이며, 계피 파우더를 뿌려 제공합니다.\\n</Document>\", \"<Document source=\\\"../data/cafe_menu_data.txt\\\">\\n7. 프라푸치노\\n   • 가격: ₩7,000\\n   • 주요 원료: 에스프레소, 우유, 얼음, 휘핑크림\\n   • 설명: 에스프레소와 우유, 얼음을 블렌더에 갈아 만든 시원한 음료입니다. 부드럽고 크리미한 질감이 특징이며, 휘핑크림을 올려 달콤함을 더했습니다. 여름철 인기 메뉴입니다.\\n</Document>\", \"<Document source=\\\"../data/cafe_menu_data.txt\\\">\\n9. 아이스 아메리카노\\n   • 가격: ₩4,500\\n   • 주요 원료: 에스프레소, 차가운 물, 얼음\\n   • 설명: 진한 에스프레소에 차가운 물과 얼음을 넣어 만든 시원한 아이스 커피입니다. 깔끔하고 시원한 맛이 특징이며, 원두 본연의 풍미를 느낄 수 있습니다. 더운 날씨에 인기가 높습니다.\\n</Document>\"]\n",
      "**** --------------------------- ****\n",
      "\n",
      "[웹 검색 질의 → LLM의 tool_calls]\n",
      "{'refusal': None,\n",
      " 'tool_calls': [{'function': {'arguments': '{\"query\": \"2023-2024\\\\ub144\\\\uc5d0 '\n",
      "                                           '\\\\uacf5\\\\uac1c\\\\ub41c '\n",
      "                                           '\\\\uc8fc\\\\uc694 '\n",
      "                                           '\\\\uc624\\\\ud508\\\\uc18c\\\\uc2a4 LLM '\n",
      "                                           '\\\\ubaa8\\\\ub378 \\\\ubaa9\\\\ub85d\"}',\n",
      "                              'name': 'search_web'},\n",
      "                 'id': 'chatcmpl-tool-bc65e50b40fd44f88f928890c56b3d00',\n",
      "                 'type': 'function'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17420\\2015373739.py:12: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tavily_search = TavilySearchResults(max_results=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ToolNode 실행 결과]\n",
      "<Document href=\"https://brunch.co.kr/@sparta/88\"/>\n",
      "brunch 매거진 AI가 서말이라도 꿰어야 보배 LLM 오픈소스는 누구나 무료로 LLM을 수정하고 활용할 수 있도록 시중에 공유되어 있는데요. 2024년 이후에 출시된 오픈소스 LLM 중 뛰어난 성능을 갖춘 모델을 소개해 드립니다. LLaMA 3은 2024년 4월 메타 AI가 공개한 오픈소스 LLM입니다. 하지만 Llama 3은 GPT-4와 달리 누구에게나 열려있는 ‘오픈소스’라는 점에서 유의미합니다. 오픈소스 LLM 중 뛰어난 성능을 보이는 Llama는 챗봇, 텍스트 번역 및 요약 등 다양한 분야에서 활용할 수 있습니다. 이미지와 같은 시각적 입력을 텍스트로 변환하여 출력하는 모델인 ‘Falcon 2 11B VLM(vision-to-language model)’도 출시 예정입니다. Falcon 2 11B 모델은 출시된 5월, 허깅 페이스에서 52,000개 이상의 다운로드 수를 기록했습니다. Gemma는 2024년 2월 구글 AI가 출시한 오픈소스 LLM입니다. * 오픈소스 \"누구나 큰일 낼 수 있어\" 누구나 큰일 낼 수 있도록, 모두를 위한 소프트웨어 교육을 만들어갑니다. brunch membership\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://www.elastic.co/kr/blog/open-source-llms-guide\"/>\n",
      "콘텐츠 생성, 번역, 분류 및 기타 다양한 사용 사례와 같은 다양한 자연어 처리(NLP) 작업을 수행하도록 훈련할 수 있는 신경망 아키텍처를 기반으로 구축되었습니다. LLM은 또한 데이터 처리 및 분석 방법을 확장하여 클라우드 보안, 검색, Observability를 향상시키는 데 중요한 역할을 할 수 있습니다. 오픈 소스 LLM을 사용하면 모든 개인이나 기업이 라이선스 비용을 지불하지 않고도 원하는 대로 LLM을 사용할 수 있습니다. GPT-NeoX-20B는 주로 연구 목적으로 개발되었으며 사용하고 맞춤 설정할 수 있는 200억 개의 매개변수가 있습니다. 이는 프롬프트에서 텍스트를 생성하도록 설계되었으며 텍스트 생성, 요약, 임베딩, 분류 및 의미 검색과 같은 특정 작업을 수행하도록 미세 조정할 수 있습니다. 이러한 기준을 사용하여 우리가 다룬 LLM 중 여러분의 고유한 상황에 가장 적합한 LLM을 결정할 수 있습니다. 이러한 모든 오픈 소스 LLM은 매우 강력하며 효과적으로 활용하면 혁신을 가져올 수 있습니다.\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://b2b.spartacodingclub.kr/blog/2024년-새로-출시된-오픈소스-llm-3가지-llm이란-오픈소스-llm-22580\"/>\n",
      "Jun 22, 2024—1.LLaMA 3​​LLaMA 3은 2024년 4월 메타 AI가 공개한 오픈소스 LLM입니다. 2023년 7월 출시하여 많은 인기를 얻은 LLaMA 2에서 더욱 발전된 모델인데요.\n",
      "</Document>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === 도구 노드 정의 ===\n",
    "tools = [search_cafe, search_web]\n",
    "tool_node = ToolNode(tools=tools)\n",
    "\n",
    "# === 1) 카페 메뉴 DB 검색 테스트 ===\n",
    "tool_call = llm_with_tools.invoke(\n",
    "    [HumanMessage(content=\"아메리카노 가격은 얼마인가요?\")]\n",
    ")\n",
    "print(\"\\n[카페 메뉴 질의 → LLM의 tool_calls]\")\n",
    "pprint(tool_call.additional_kwargs)\n",
    "\n",
    "# ToolNode 실행 (실제 search_cafe 동작)\n",
    "results = tool_node.invoke({\"messages\": [tool_call]})\n",
    "print(\"\\n[ToolNode 실행 결과]\")\n",
    "for result in results['messages']:\n",
    "    print(type(result))\n",
    "    print(result.content)\n",
    "    print('**** --------------------------- ****')\n",
    "\n",
    "# === 2) 웹 검색(Tavily) 테스트 ===\n",
    "tool_call = llm_with_tools.invoke(\n",
    "    [HumanMessage(content=\"최근에 공개된 오픈소스 LLM 모델은 어떤 것들이 있나요?\")]\n",
    ")\n",
    "print(\"\\n[웹 검색 질의 → LLM의 tool_calls]\")\n",
    "pprint(tool_call.additional_kwargs)\n",
    "\n",
    "results = tool_node.invoke({\"messages\": [tool_call]})\n",
    "print(\"\\n[ToolNode 실행 결과]\")\n",
    "for result in results['messages']:\n",
    "    print(result.content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d876bc",
   "metadata": {},
   "source": [
    "## ReAct Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcf02e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[카페 메뉴 질의 응답]\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "아메리카노 가격은 얼마인가요?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[아메리카노 가격을 확인하기 위해 `search_cafe` 함수를 호출하는 것이 필수적입니다. 이 함수는 카페 메뉴 데이터베이스에서 가격 정보를 직접 검색하므로, 질문에 대한 정확한 답변을 제공할 수 있습니다. 웹 검색(`search_web`)은 최신 정보보다는 DB 내 기본 가격 조회에 불필요합니다.]\n",
      "Tool Calls:\n",
      "  search_cafe (chatcmpl-tool-a621e6b59d28464c868dca4d840df1f9)\n",
      " Call ID: chatcmpl-tool-a621e6b59d28464c868dca4d840df1f9\n",
      "  Args:\n",
      "    query: 아메리카노 가격\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search_cafe\n",
      "\n",
      "[\"<Document source=\\\"../data/cafe_menu_data.txt\\\">\\n4. 바닐라 라떼\\n   • 가격: ₩6,000\\n   • 주요 원료: 에스프레소, 스팀 밀크, 바닐라 시럽\\n   • 설명: 카페라떼에 달콤한 바닐라 시럽을 더한 인기 메뉴입니다. 바닐라의 달콤함과 커피의 쌉싸름함이 조화롭게 어우러지며, 휘핑크림 토핑으로 더욱 풍성한 맛을 즐길 수 있습니다.\\n</Document>\", \"<Document source=\\\"../data/cafe_menu_data.txt\\\">\\n2. 카페라떼\\n   • 가격: ₩5,500\\n   • 주요 원료: 에스프레소, 스팀 밀크\\n   • 설명: 진한 에스프레소에 부드럽게 스팀한 우유를 넣어 만든 대표적인 밀크 커피입니다. 크리미한 질감과 부드러운 맛이 특징이며, 다양한 시럽과 토핑 추가가 가능합니다. 라떼 아트로 시각적 즐거움도 제공합니다.\\n</Document>\", \"<Document source=\\\"../data/cafe_menu_data.txt\\\">\\n3. 카푸치노\\n   • 가격: ₩5,000\\n   • 주요 원료: 에스프레소, 스팀 밀크, 우유 거품\\n   • 설명: 에스프레소, 스팀 밀크, 우유 거품이 1:1:1 비율로 구성된 이탈리아 전통 커피입니다. 진한 커피 맛과 부드러운 우유 거품의 조화가 일품이며, 계피 파우더를 뿌려 제공합니다.\\n</Document>\", \"<Document source=\\\"../data/cafe_menu_data.txt\\\">\\n7. 프라푸치노\\n   • 가격: ₩7,000\\n   • 주요 원료: 에스프레소, 우유, 얼음, 휘핑크림\\n   • 설명: 에스프레소와 우유, 얼음을 블렌더에 갈아 만든 시원한 음료입니다. 부드럽고 크리미한 질감이 특징이며, 휘핑크림을 올려 달콤함을 더했습니다. 여름철 인기 메뉴입니다.\\n</Document>\", \"<Document source=\\\"../data/cafe_menu_data.txt\\\">\\n9. 아이스 아메리카노\\n   • 가격: ₩4,500\\n   • 주요 원료: 에스프레소, 차가운 물, 얼음\\n   • 설명: 진한 에스프레소에 차가운 물과 얼음을 넣어 만든 시원한 아이스 커피입니다. 깔끔하고 시원한 맛이 특징이며, 원두 본연의 풍미를 느낄 수 있습니다. 더운 날씨에 인기가 높습니다.\\n</Document>\"]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "아메리카노 가격은 다음과 같습니다:  \n",
      "- **아이스 아메리카노**: ₩4,500  \n",
      "\n",
      "핫 아메리카노 가격은 제공된 메뉴 데이터에 명시되어 있지 않습니다. 해당 정보가 필요한 경우 추가 검색이 필요할 수 있습니다.\n",
      "\n",
      "[웹 검색 질의 응답]\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "최근에 공개된 오픈소스 LLM 모델은 어떤 것들이 있나요?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[최신 오픈소스 LLM 모델 정보는 카페 DB에 없을 수 있으며, 웹 검색을 통해 가장 정확한 최신 정보를 제공할 수 있기 때문에 ESSENTIAL합니다]  \n",
      "\n",
      "### 참고: 일반 지식 기반 답변 (보조 설명)  \n",
      "2023년~2024년 초 공개된 대표적인 오픈소스 LLM에는 다음과 같은 모델들이 있습니다(웹 검색 결과와 비교 필요):  \n",
      "- **Llama 3** (Meta)  \n",
      "- **Mixtral 8x7B** (Mistral AI)  \n",
      "- **Phi-3** (Microsoft)  \n",
      "- **SOLAR Pro 2** (Upstage)  \n",
      "- **Falcon 2** (TII)  \n",
      "\n",
      "단, 정확한 최신 목록은 웹 검색을 통해 확인해야 합니다.\n",
      "Tool Calls:\n",
      "  search_web (chatcmpl-tool-84e9fefdab4f4c4c8e997b3f07cc9b3b)\n",
      " Call ID: chatcmpl-tool-84e9fefdab4f4c4c8e997b3f07cc9b3b\n",
      "  Args:\n",
      "    query: 2023-2024 recently released open-source LLM models\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search_web\n",
      "\n",
      "<Document href=\"https://www.datacamp.com/blog/top-open-source-llms\"/>\n",
      "Released on July 23, 2024, LLaMA 3.1 includes models with 8B, 70B, and for the first time, 405B parameters, making it the largest in the series. These models have been designed to handle a variety of natural language processing tasks across multiple languages including English, Spanish, Portuguese, German, Thai, French, Italian, and Hindi. [...] With open-source LLM, researchers have more chances to know about this information, which can open the door for new improvements designed to reduce the environmental footprint of AI.\n",
      "\n",
      "## 9 Top Open-Source Large Language Models For 2024\n",
      "\n",
      "### 1. LLaMA 3.1\n",
      "\n",
      "Most top players in the LLM space have opted to build their LLM behind closed doors. However, Meta continues to be an exception with its series of open-source LLMs, which now includes the latest LLaMA 3.1. [...] Released by the Technology Innovation Institute of the United Arab Emirates in September 2023, Falcon 180B is being trained on 180 billion parameters and 3.5 trillion tokens. With this impressive computing power, Falcon 180B has already outperformed LLaMA 2 and GPT-3.5 in various NLP tasks, and Hugging Face suggests it can rival Google’s PaLM 2, the LLM that powers Google Bard.\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://agentestudio.com/blog/%2Ftop-open-source-llms\"/>\n",
      "09 May 2024\n",
      "\n",
      "# Top 7 Open-Source LLMs for 2024\n",
      "\n",
      "AI Development\n",
      "\n",
      "Open source LLM models have come a long way since their inception. Once confined to research labs, these AI systems have steadily grown in size and sophistication, now capable of processing vast amounts of information and generating human-quality text, translations, and even creative content. [...] ### Bard - (Google AI, released 2023)\n",
      "\n",
      "Developed by Google AI, Bard stands out for its ability to access and process real-time information, allowing for responses that are grounded in current events and factual updates. This makes it a valuable tool for tasks requiring up-to-date information, such as summarizing news articles or generating content based on recent trends. However, Bard is still under development and may not be as comprehensive or polished as some other established models. [...] As the field of LLMs continues to grow and evolve, open-source models are poised to play a significant role in democratizing access to this powerful technology and fostering innovation across various domains. By understanding the benefits, limitations, and current landscape of open-source LLMs, users can make informed decisions about whether these models are suitable for their specific needs and contribute to the responsible development and deployment of this transformative technology.\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://github.com/eugeneyan/open-llms\"/>\n",
      "| FLOR | 2023/12 | FLOR-760M, FLOR-1.3B, FLOR-1.3B-Instructed, FLOR-6.3B, FLOR-6.3B-Instructed | FLOR-6.3B: a chinchilla-compliant model for Catalan, Spanish and English | 0.76, 1.3, 6.3 | 2048 | Apache 2.0 with usage restriction inherited from BLOOM |  |\n",
      "| RWKV 5 v2 | 2024/01 | rwkv-5-world-0.4b-2, rwkv-5-world-1.5b-2, rwkv-5-world-3b-2, rwkv-5-world-3b-2(16k), rwkv-5-world-7b-2 | RWKV 5 | 0.4, 1.5, 3, 7 | unlimited(RNN), trained on 4096 (and 16k for 3b) | Apache 2.0 |  | [...] | Fugaku-LLM | 2024/05 | Fugaku-LLM-13B, Fugaku-LLM-13B-instruct | Release of \"Fugaku-LLM\" – a large language model trained on the supercomputer \"Fugaku\" | 13 | 2048 | Custom Free with usage restrictions |  |\n",
      "| Falcon 2 | 2024/05 | falcon2-11B | Meet Falcon 2: TII Releases New AI Model Series, Outperforming Meta’s New Llama 3 | 11 | 8192 | Custom Apache 2.0 with mild acceptable use policy |  | [...] | Gemma | 2024/02 | Gemma 7B, Gemma 7B it, Gemma 2B, Gemma 2B it | Technical report | 2-7 | 8192 | Gemma Terms of Use Free with usage restriction and models trained on Gemma outputs become Gemma derivatives, subject to this license. |  |\n",
      "| Grok-1 | 2024/03 | Grok-1 | Open Release of Grok-1 | 314 | 8192 | Apache 2.0 |  |\n",
      "</Document>\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "최근 공개된 오픈소스 LLM 모델들은 다음과 같습니다. 웹 검색을 통해 확인된 2024년 상반기 기준 주요 모델들을 정리했습니다:\n",
      "\n",
      "1. **LLaMA 3.1** (Meta, 2024년 7월)  \n",
      "   - 8B, 70B, 405B 파라미터 버전 제공  \n",
      "   - 영어 외 8개 언어 지원 (스페인어, 포르투갈어 등)  \n",
      "   - *최신 버전*으로 가장 큰 규모(405B)를 자랑\n",
      "\n",
      "2. **Falcon 2** (TII, 2024년 5월)  \n",
      "   - 11B 파라미터 모델  \n",
      "   - Llama 3 성능 초과 보고됨  \n",
      "   - 컨텍스트 길이 8,192 토큰 지원\n",
      "\n",
      "3. **Gemma 2** (Google, 2024년 2월)  \n",
      "   - 2B 및 7B 파라미터 버전  \n",
      "   - Gemini Nano 기반 경량화 모델  \n",
      "   - 온디바이스 AI용으로 최적화\n",
      "\n",
      "4. **Grok-1** (xAI, 2024년 3월)  \n",
      "   - 314B 파라미터 모델  \n",
      "   - Apache 2.0 라이선스 적용  \n",
      "   - 실시간 정보 처리 강점\n",
      "\n",
      "5. **Fugaku-LLM** (일본 RIKEN, 2024년 5월)  \n",
      "   - 13B 파라미터 모델  \n",
      "   - 슈퍼컴퓨터 '후가쿠'로 훈련  \n",
      "   - 일본어 특화 성능\n",
      "\n",
      "6. **Mixtral 8x7B** (Mistral AI, 2024년 초)  \n",
      "   - MoE(Mixture of Experts) 아키텍처  \n",
      "   - 45B 파라미터 효율성  \n",
      "   - 코드 생성 및 복잡한 추론에 강점\n",
      "\n",
      "7. **Phi-3** (Microsoft, 2024년 4월)  \n",
      "   - 3.8B 파라미터 모델  \n",
      "   - 소규모 모델임에도 뛰어난 성능  \n",
      "   - 소규모 하드웨어에서도 실행 가능\n",
      "\n",
      "> **참고**: LLaMA 3.1의 405B 버전은 현재 공개된 오픈소스 LLM 중 가장 큰 규모입니다. 모델 선택 시 파라미터 규모, 지원 언어, 라이선스(Apache 2.0 등), 사용 제한 사항을 반드시 확인해야 합니다. 최신 정보는 [Hugging Face](https://huggingface.co/models) 또는 [PapersWithCode](https://paperswithcode.com/sota)에서 확인할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# === 1) 도구 목록 (카페 DB + 웹 검색) ===\n",
    "tools = [search_cafe, search_web]\n",
    "\n",
    "# === 2) ReAct Agent 생성 ===\n",
    "agent = create_react_agent(\n",
    "    llm, \n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "# === 3) 카페 메뉴 질의 테스트 ===\n",
    "inputs = {\"messages\": [HumanMessage(content=\"아메리카노 가격은 얼마인가요?\")]}\n",
    "messages = agent.invoke(inputs)\n",
    "\n",
    "print(\"\\n[카페 메뉴 질의 응답]\")\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()\n",
    "\n",
    "# === 4) 웹 검색 질의 테스트 ===\n",
    "inputs = {\"messages\": [HumanMessage(content=\"최근에 공개된 오픈소스 LLM 모델은 어떤 것들이 있나요?\")]}\n",
    "messages = agent.invoke(inputs)\n",
    "\n",
    "print(\"\\n[웹 검색 질의 응답]\")\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
