{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0fa4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8264ea0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIza\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "print(GOOGLE_API_KEY[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d93f00ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Google Gemini Response:\n",
      "네, AI 전문가로서 LangChain과 LangGraph에 대해 명확하고 이해하기 쉽게 설명해 드리겠습니다.\n",
      "\n",
      "이 둘은 LLM(거대 언어 모델)을 활용한 애플리케이션을 더 쉽고 강력하게 만들 수 있도록 돕는 도구(프레임워크)이며, 서로 밀접한 관련이 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. LangChain (랭체인): LLM 애플리케이션을 위한 '레고 블록'\n",
      "\n",
      "**LangChain은 LLM을 단독으로 사용하는 것을 넘어, 다른 외부 데이터나 서비스와 연결하여 강력한 애플리케이션을 만들 수 있도록 도와주는 개발 프레임워크**입니다.\n",
      "\n",
      "LLM은 그 자체로도 훌륭하지만, 최신 정보에 접근하거나 특정 계산을 수행하거나, 외부 API를 호출하는 능력은 없습니다. LangChain은 이러한 한계를 극복하기 위한 다양한 '구성 요소(Components)'를 제공합니다. 마치 레고 블록을 조립해 원하는 것을 만드는 것과 같습니다.\n",
      "\n",
      "#### 핵심 개념 (레고 블록의 종류)\n",
      "\n",
      "*   **Models**: OpenAI의 GPT, Anthropic의 Claude 등 다양한 LLM 모델에 쉽게 연결할 수 있는 인터페이스입니다.\n",
      "*   **Prompts**: LLM에게 전달할 지시문(프롬프트)을 동적으로 생성하고 관리하는 템플릿 기능입니다.\n",
      "*   **Chains**: LangChain의 가장 핵심적인 개념으로, **'LLM 호출'과 다른 구성 요소들을 순차적으로 연결하는 것**을 의미합니다. 예를 들어, `(사용자 질문 -> 프롬프트 생성 -> LLM 호출 -> 결과 파싱)`과 같은 일련의 과정을 하나의 '체인'으로 묶을 수 있습니다.\n",
      "*   **Indexes & Retrievers (RAG)**: PDF, DB 등 외부 데이터를 LLM이 참조할 수 있도록 색인(Index)하고, 사용자의 질문과 관련된 부분을 효율적으로 찾아(Retrieve)주는 기능입니다. 이를 통해 LLM이 학습하지 않은 최신 정보나 특정 도메인 지식에 대해 답변하게 만들 수 있습니다. (이것이 바로 **RAG, 검색 증강 생성**의 핵심입니다.)\n",
      "*   **Agents**: LLM이 단순히 텍스트만 생성하는 것을 넘어, **'생각'하고 '도구(Tools)'를 사용해 스스로 문제를 해결**하도록 만드는 기능입니다. 예를 들어 \"오늘 파리 날씨를 알려주고, 한국어로 번역해 줘\"라는 요청에 대해, 에이전트는 스스로 '날씨 검색 API'라는 도구를 사용해 날씨를 찾고, '번역'이라는 도구를 사용해 결과를 번역해서 보여줍니다.\n",
      "*   **Memory**: 대화의 이전 내용을 기억하게 하여, 챗봇처럼 자연스러운 대화를 이어갈 수 있게 하는 기능입니다.\n",
      "\n",
      "> **한마디로 LangChain은?**\n",
      "> LLM을 중심으로 다양한 부품(데이터, API, 메모리 등)을 **순차적으로(linearly)** 연결하여 애플리케이션을 만드는 조립 키트입니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. LangGraph (랭그래프): 복잡한 워크플로우를 위한 '스마트 순서도'\n",
      "\n",
      "**LangGraph는 LangChain을 기반으로, 더 복잡하고, 순환적이며, 상태(State)를 관리해야 하는 LLM 애플리케이션을 만들기 위해 등장한 라이브러리**입니다.\n",
      "\n",
      "LangChain의 'Chain'은 기본적으로 A -> B -> C 와 같이 한 방향으로 흐르는 선형적인 구조(DAG, Directed Acyclic Graph)에 강점이 있습니다. 하지만 여러 에이전트가 협업하거나, 작업 결과를 평가하고 만족스럽지 않으면 다시 이전 단계로 돌아가 재시도하는 등의 **'순환(Cycle)'이 필요한 작업**에는 한계가 있었습니다.\n",
      "\n",
      "LangGraph는 이러한 흐름을 '그래프(Graph)' 형태로 제어할 수 있게 해줍니다.\n",
      "\n",
      "#### 핵심 개념\n",
      "\n",
      "*   **State**: 그래프의 전체 작업 흐름 동안 유지되고 업데이트되는 중앙 데이터 객체입니다. 각 단계(노드)는 이 '상태'를 읽고 수정할 수 있습니다.\n",
      "*   **Nodes**: 그래프의 각 단계를 나타내는 '작업 단위'입니다. 각 노드는 함수나 LangChain의 체인이 될 수 있습니다. (예: '웹 검색 노드', '보고서 작성 노드', '결과 검토 노드')\n",
      "*   **Edges**: 한 노드에서 다음 노드로 어떻게 이동할지를 결정하는 '연결선'이자 '로직'입니다. 특히 **조건부 엣지(Conditional Edges)**가 핵심인데, 현재 '상태'에 따라 다음에 실행할 노드를 동적으로 결정할 수 있습니다. (예: '결과 검토 노드'가 결과를 보고 \"만족스러우면\" -> '종료 노드'로, \"불만족스러우면\" -> '웹 검색 노드'로 다시 돌아가도록 분기시킬 수 있습니다.)\n",
      "\n",
      "> **한마디로 LangGraph는?**\n",
      "> 작업의 '상태'를 중심으로, 각 단계(노드)를 실행하고 그 결과에 따라 다음 단계를 동적으로 결정하는, **순환과 분기가 가능한 지능형 워크플로우 엔진**입니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 핵심 차이점 및 관계 요약\n",
      "\n",
      "| 구분 | **LangChain** | **LangGraph** |\n",
      "| :--- | :--- | :--- |\n",
      "| **핵심 추상화** | **체인 (Chain)** | **그래프 (Graph)** |\n",
      "| **제어 흐름** | **선형적 (Linear), 단방향 (DAG)** | **순환적 (Cyclical), 상태 기반 (Stateful)** |\n",
      "| **주요 사용 사례** | 간단한 RAG 챗봇, 데이터 요약, 순차적 도구 사용 | 다중 에이전트 협업, 재시도/수정이 필요한 복잡한 작업, Human-in-the-loop |\n",
      "| **핵심 기능** | LLM 구성 요소의 조합 및 연결 | 상태 관리, 조건부 분기, 순환(루프) 제어 |\n",
      "| **비유** | **레고 조립 설명서** (정해진 순서대로 조립) | **스마트 순서도** (조건에 따라 다른 경로로 이동하거나 되돌아감) |\n",
      "\n",
      "### 결론: 어떤 것을 사용해야 할까요?\n",
      "\n",
      "*   **\"특정 문서에 대해 질문하고 답변하는 챗봇을 만들고 싶다\"** 와 같이 작업 흐름이 비교적 단순하고 순차적이라면 **LangChain**으로 충분하고 가장 효율적입니다.\n",
      "*   **\"리서처 에이전트가 웹 검색을 하고, 작성자 에이전트가 초안을 쓰고, 비평가 에이전트가 검토 후 피드백을 주면, 작성자 에이전트가 다시 수정하는 시스템을 만들고 싶다\"** 와 같이 여러 단계가 상호작용하고, 순환하며, 상태를 공유해야 한다면 **LangGraph**가 필수적입니다.\n",
      "\n",
      "결론적으로, **LangGraph는 LangChain의 기능을 확장하여, 훨씬 더 복잡하고 지능적인 자율 에이전트 및 워크플로우를 구현할 수 있게 해주는 강력한 도구**라고 이해하시면 됩니다. 대부분의 프로젝트는 LangChain으로 시작하며, 필요에 따라 복잡한 제어 흐름을 위해 LangGraph를 도입하게 됩니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "    \n",
    "# API 키 설정\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"your-google-api-key\"\n",
    "\n",
    "# 모델 초기화\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    #model=\"gemini-1.5-flash\",\n",
    "    model=\"gemini-2.5-pro\",\n",
    "    temperature=0.3    \n",
    ")\n",
    "\n",
    "# 프롬프트 설정\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 AI 전문가입니다.\"),\n",
    "    (\"human\", \"{topic}은(는) 무엇인가요?\")\n",
    "])\n",
    "\n",
    "# 체인 실행\n",
    "chain = prompt | llm\n",
    "response = chain.invoke({\"topic\": \"LangChain과 LangGraph\"})\n",
    "\n",
    "print(\" Google Gemini Response:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99bcfff",
   "metadata": {},
   "source": [
    "#### Gemini 모델별 특징\n",
    "\n",
    "* gemini-1.5-flash: 빠른 응답, 일반적인 작업에 적합\n",
    "* gemini-2.5-pro: 더 정확하고 복잡한 추론 작업\n",
    "* gemini-pro-vision: 이미지 처리 및 멀티모달 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37613cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "예제 1: 기본 대화형 챗봇\n",
      "==================================================\n",
      "응답: 안녕하세요! 파이썬으로 리스트를 정렬하는 방법은 아주 간단하고 강력해요. 주로 두 가지 방법을 사용하는데, 상황에 맞게 골라 쓰시면 됩니다.\n",
      "\n",
      "바로 `sort()` 메소드와 `sorted()` 내장 함수입니다. 하나씩 자세히 알아볼까요?\n",
      "\n",
      "### 1. `list.sort()` 메소드: 리스트 자체를 정렬하기\n",
      "\n",
      "이 방법은 리스트 **자체**를 직접 수정하여 정렬합니다 (in-place 정렬). 반환값은 `None`이에요. 원래 리스트의 순서가 필요 없다면 이 방법을 사용하는 것이 효율적입니다.\n",
      "\n",
      "#### 기본 사용법 (오름차순)\n",
      "\n",
      "```python\n",
      "numbers = [3, 1, 4, 1, 5, 9, 2]\n",
      "print(f\"정렬 전: {numbers}\")\n",
      "\n",
      "# 리스트 자체를 정렬합니다. 반환값은 None입니다.\n",
      "numbers.sort() \n",
      "\n",
      "print(f\"정렬 후: {numbers}\")\n",
      "```\n",
      "\n",
      "**결과:**\n",
      "```\n",
      "정렬 전: [3, 1, 4, 1, 5, 9, 2]\n",
      "정렬 후: [1, 1, 2, 3, 4, 5, 9]\n",
      "```\n",
      "\n",
      "#### 내림차순 정렬 (`reverse=True`)\n",
      "\n",
      "`reverse` 옵션을 `True`로 설정하면 내림차순으로 정렬할 수 있습니다.\n",
      "\n",
      "```python\n",
      "numbers = [3, 1, 4, 1, 5, 9, 2]\n",
      "numbers.sort(reverse=True)\n",
      "print(f\"내림차순 정렬 후: {numbers}\")\n",
      "```\n",
      "\n",
      "**결과:**\n",
      "```\n",
      "내림차순 정렬 후: [9, 5, 4, 3, 2, 1, 1]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### 2. `sorted()` 내장 함수: 새로운 정렬된 리스트 만들기\n",
      "\n",
      "이 함수는 **원본 리스트는 그대로 두고**, 정렬된 **새로운 리스트를 반환**합니다. 원본 데이터의 순서를 보존해야 할 때 아주 유용하죠. 리스트뿐만 아니라 튜플, 문자열 등 반복 가능한(iterable) 모든 것을 정렬할 수 있습니다.\n",
      "\n",
      "#### 기본 사용법 (오름차순)\n",
      "\n",
      "```python\n",
      "numbers = [3, 1, 4, 1, 5, 9, 2]\n",
      "print(f\"원본 리스트: {numbers}\")\n",
      "\n",
      "# 정렬된 '새로운' 리스트를 반환합니다.\n",
      "new_sorted_list = sorted(numbers)\n",
      "\n",
      "print(f\"새로운 정렬된 리스트: {new_sorted_list}\")\n",
      "print(f\"정렬 후 원본 리스트: {numbers}\") # 원본은 변경되지 않음!\n",
      "```\n",
      "\n",
      "**결과:**\n",
      "```\n",
      "원본 리스트: [3, 1, 4, 1, 5, 9, 2]\n",
      "새로운 정렬된 리스트: [1, 1, 2, 3, 4, 5, 9]\n",
      "정렬 후 원본 리스트: [3, 1, 4, 1, 5, 9, 2]\n",
      "```\n",
      "\n",
      "#### 내림차순 정렬 (`reverse=True`)\n",
      "\n",
      "`sort()`와 마찬가지로 `reverse=True` 옵션을 사용할 수 있습니다.\n",
      "\n",
      "```python\n",
      "numbers = [3, 1, 4, 1, 5, 9, 2]\n",
      "desc_list = sorted(numbers, reverse=True)\n",
      "print(f\"내림차순으로 정렬된 새 리스트: {desc_list}\")\n",
      "```\n",
      "\n",
      "**결과:**\n",
      "```\n",
      "내림차순으로 정렬된 새 리스트: [9, 5, 4, 3, 2, 1, 1]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### 심화: `key`를 이용한 정렬 기준 설정\n",
      "\n",
      "두 방법 모두 `key` 매개변수를 사용하여 더 복잡한 기준으로 정렬할 수 있습니다. `key`에는 각 요소에 적용할 함수를 지정합니다. 보통 `lambda` 함수와 함께 많이 쓰여요.\n",
      "\n",
      "**예시: 튜플 리스트를 두 번째 요소(점수) 기준으로 정렬하기**\n",
      "\n",
      "```python\n",
      "students = [('홍길동', 90), ('이순신', 95), ('강감찬', 85)]\n",
      "\n",
      "# 점수(튜플의 1번 인덱스)를 기준으로 정렬\n",
      "# sorted() 함수 사용\n",
      "sorted_by_score = sorted(students, key=lambda student: student[1])\n",
      "print(f\"점수 기준 오름차순 정렬: {sorted_by_score}\")\n",
      "\n",
      "# 점수 높은 순(내림차순)으로 정렬\n",
      "sorted_by_score_desc = sorted(students, key=lambda student: student[1], reverse=True)\n",
      "print(f\"점수 기준 내림차순 정렬: {sorted_by_score_desc}\")\n",
      "```\n",
      "**결과:**\n",
      "```\n",
      "점수 기준 오름차순 정렬: [('강감찬', 85), ('홍길동', 90), ('이순신', 95)]\n",
      "점수 기준 내림차순 정렬: [('이순신', 95), ('홍길동', 90), ('강감찬', 85)]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### `sort()` vs `sorted()` 핵심 비교\n",
      "\n",
      "| 특징 | `list.sort()` | `sorted()` |\n",
      "| :--- | :--- | :--- |\n",
      "| **동작 방식** | 리스트 **자체**를 수정 (In-place) | 정렬된 **새로운 리스트**를 반환 |\n",
      "| **반환값** | `None` | 정렬된 새로운 리스트 |\n",
      "| **적용 대상** | 리스트(list)에만 사용 가능 | 모든 반복 가능한 객체(iterable) 가능 |\n",
      "| **원본 유지** | 원본이 변경됨 | 원본이 그대로 유지됨 |\n",
      "\n",
      "### 언제 무엇을 사용해야 할까요?\n",
      "\n",
      "*   **`list.sort()`**: 원본 리스트가 더 이상 필요 없고, 메모리를 절약하고 싶을 때 사용합니다.\n",
      "*   **`sorted()`**: 원본 리스트를 그대로 유지해야 할 때, 또는 튜플이나 다른 반복 가능한 객체를 정렬할 때 사용합니다. **일반적으로 더 안전하고 자주 사용되는 방법입니다.**\n",
      "\n",
      "이 두 가지 방법만 잘 알아두시면 파이썬에서 리스트 정렬은 문제없으실 거예요! 혹시 더 궁금한 점이 있으시면 언제든지 다시 물어보세요. 😊\n",
      "\n",
      "==================================================\n",
      "예제 2: JSON 구조화 출력\n",
      "==================================================\n",
      "JSON 결과: ```json\n",
      "{\n",
      "  \"name\": \"네이버\",\n",
      "  \"year\": \"1999\",\n",
      "  \"location\": \"경기도 성남\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# API 키 설정\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"your-google-api-key\"\n",
    "\n",
    "# 기본 모델 설정\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    #model=\"gemini-1.5-flash\",\n",
    "    model=\"gemini-2.5-pro\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"예제 1: 기본 대화형 챗봇\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 대화형 프롬프트\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 친근하고 도움이 되는 AI 어시스턴트입니다.\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "chat_chain = chat_prompt | llm | StrOutputParser()\n",
    "response1 = chat_chain.invoke({\"user_input\": \"파이썬으로 리스트를 정렬하는 방법은?\"})\n",
    "print(\"응답:\", response1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 2: JSON 구조화 출력\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "json_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "다음 정보를 JSON 형태로 변환하세요:\n",
    "{company_info}\n",
    "\n",
    "형식: {{\"name\": \"회사명\", \"year\": \"연도\", \"location\": \"위치\"}}\n",
    "\"\"\",\n",
    "    input_variables=[\"company_info\"]\n",
    ")\n",
    "\n",
    "json_chain = json_prompt | llm | StrOutputParser()\n",
    "company_text = \"네이버는 1999년에 설립된 한국의 IT 기업이며 본사는 경기도 성남에 있습니다.\"\n",
    "response2 = json_chain.invoke({\"company_info\": company_text})\n",
    "print(\"JSON 결과:\", response2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2331af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 3: 번역 체인\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "translate_prompt = ChatPromptTemplate.from_template(\n",
    "    \"다음 텍스트를 {target_language}로 번역하세요: {text}\"\n",
    ")\n",
    "\n",
    "translate_chain = translate_prompt | llm | StrOutputParser()\n",
    "original = \"Hello, how are you today?\"\n",
    "translated = translate_chain.invoke({\n",
    "    \"text\": original, \n",
    "    \"target_language\": \"한국어\"\n",
    "})\n",
    "print(\"번역 결과:\", translated)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 4: 감정 분석\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "emotion_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "텍스트: {text}\n",
    "감정을 분석하고 [긍정/부정/중립]과 1-10점수를 매기세요.\n",
    "\"\"\")\n",
    "\n",
    "emotion_chain = emotion_prompt | llm | StrOutputParser()\n",
    "test_text = \"오늘 프로젝트가 성공적으로 완료되어서 정말 기쁩니다!\"\n",
    "emotion_result = emotion_chain.invoke({\"text\": test_text})\n",
    "print(\"감정 분석:\", emotion_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 5: 코드 생성\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "code_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "{language}로 {task} 기능을 구현하는 간단한 코드를 작성하세요.\n",
    "\"\"\")\n",
    "\n",
    "code_chain = code_prompt | llm | StrOutputParser()\n",
    "code_result = code_chain.invoke({\n",
    "    \"language\": \"Python\",\n",
    "    \"task\": \"두 숫자의 최대공약수를 구하는\"\n",
    "})\n",
    "print(\"생성된 코드:\")\n",
    "print(code_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 6: 창의적 콘텐츠 생성\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001da18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 창의적 생성용 높은 temperature\n",
    "llm_creative = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.9\n",
    ")\n",
    "\n",
    "creative_prompt = ChatPromptTemplate.from_template(\n",
    "    \"{topic}에 대한 창의적인 {content_type}를 {style} 스타일로 작성하세요.\"\n",
    ")\n",
    "\n",
    "creative_chain = creative_prompt | llm_creative | StrOutputParser()\n",
    "creative_result = creative_chain.invoke({\n",
    "    \"topic\": \"미래의 교통수단\",\n",
    "    \"content_type\": \"아이디어\",\n",
    "    \"style\": \"혁신적이고 실현 가능한\"\n",
    "})\n",
    "print(\"창의적 아이디어:\", creative_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Gemini 모델 옵션\")\n",
    "print(\"=\" * 50)\n",
    "print(\"• gemini-1.5-flash: 빠른 응답, 일반 작업\")\n",
    "print(\"• gemini-1.5-pro: 정확한 분석, 복잡한 추론\")\n",
    "print(\"• gemini-pro-vision: 이미지 처리 가능\")\n",
    "print(\"• temperature: 0.1(정확) ~ 0.9(창의적)\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
