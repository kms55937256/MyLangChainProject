{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain!!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello LangChain!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_w\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "#load_dotenv(dotenv_path='.env')\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.chat.ChatPromptTemplate'>\n",
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt + llm + output \n",
    "\n",
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.\") , \n",
    "     (\"user\", \"{input}\") ]\n",
    ")\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "System: ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.\n",
      "Human: íŒŒì´ì¬ì€ ë¬´ì—‡ì¸ê°€ìš”? ìì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”\n"
     ]
    }
   ],
   "source": [
    "prompt_text = prompt.format(input=\"íŒŒì´ì¬ì€ ë¬´ì—‡ì¸ê°€ìš”? ìì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”\")\n",
    "print(type(prompt_text))\n",
    "print(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_openai.chat_models.base.ChatOpenAI'>\n",
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001E1163E98B0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001E1163EA300> root_client=<openai.OpenAI object at 0x000001E1163E99A0> root_async_client=<openai.AsyncOpenAI object at 0x000001E1163E9CA0> model_name='openai/gpt-oss-120b' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "#llm = ChatOpenAI(api_key=OPENAI_API_KEY, model_name=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# Groq APIë¥¼ ì‚¬ìš©í•˜ëŠ” ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    #model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(type(llm))\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "ì‘ë‹µ: ## íŒŒì´ì¬(Python)ì´ë€?\n",
      "\n",
      "íŒŒì´ì¬ì€ **ê³ ìˆ˜ì¤€(highâ€‘level), ì¸í„°í”„ë¦¬í„°(interpreted), ë™ì  íƒ€ì´í•‘(dynamic typing)** ì–¸ì–´ì´ë©°, **ë²”ìš© í”„ë¡œê·¸ë˜ë° ì–¸ì–´(generalâ€‘purpose)** ë¡œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. 1991ë…„ ë„¤ëœë€ë“œì˜ ê·€ë„ ë°˜ ë¡œì„¬(Guido van Rossum)ì´ ì²˜ìŒ ë°œí‘œí–ˆìœ¼ë©°, í˜„ì¬ëŠ” ì „ ì„¸ê³„ ìˆ˜ë§ì€ ê°œë°œìì™€ ê¸°ì—…ì´ ì‚¬ìš©í•˜ê³  ìˆëŠ” ê°€ì¥ ì¸ê¸° ìˆëŠ” ì–¸ì–´ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. íŒŒì´ì¬ì˜ ì£¼ìš” íŠ¹ì§•\n",
      "\n",
      "| íŠ¹ì§• | ì„¤ëª… |\n",
      "|------|------|\n",
      "| **ì½ê¸° ì‰¬ìš´ ë¬¸ë²•** | ì½”ë“œê°€ ìì—°ì–´ì— ê°€ê¹ê²Œ ì„¤ê³„ë¼ ì´ˆë³´ìë„ ì´í•´í•˜ê¸° ì‰½ìŠµë‹ˆë‹¤. ë“¤ì—¬ì“°ê¸°(Indentation)ë§Œìœ¼ë¡œ ë¸”ë¡ì„ êµ¬ë¶„í•©ë‹ˆë‹¤. |\n",
      "| **ë™ì  íƒ€ì´í•‘** | ë³€ìˆ˜ ì„ ì–¸ ì‹œ íƒ€ì…ì„ ëª…ì‹œí•˜ì§€ ì•Šì•„ë„ ëŸ°íƒ€ì„ì— ìë™ìœ¼ë¡œ ê²°ì •ë©ë‹ˆë‹¤. (`x = 10`, `x = \"hello\"` ê°€ëŠ¥) |\n",
      "| **ì¸í„°í”„ë¦¬í„° ì–¸ì–´** | ì½”ë“œë¥¼ í•œ ì¤„ì”© ì‹¤í–‰í•´ ë°”ë¡œ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆì–´ ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. |\n",
      "| **ë©€í‹°íŒ¨ëŸ¬ë‹¤ì„** | ì ˆì°¨ì , ê°ì²´ì§€í–¥, í•¨ìˆ˜í˜• í”„ë¡œê·¸ë˜ë°ì„ ëª¨ë‘ ì§€ì›í•©ë‹ˆë‹¤. |\n",
      "| **í’ë¶€í•œ í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬** | íŒŒì¼ ì…ì¶œë ¥, ë„¤íŠ¸ì›Œí‚¹, ë°ì´í„° ì§ë ¬í™”, ì›¹ ì„œë²„ ë“± 2,000ê°œ ì´ìƒì˜ ëª¨ë“ˆì´ ê¸°ë³¸ ì œê³µë©ë‹ˆë‹¤. |\n",
      "| **í™•ì¥ì„±** | C, C++, Rust ë“±ìœ¼ë¡œ ì‘ì„±ëœ ëª¨ë“ˆì„ ì‰½ê²Œ ì—°ê²°í•´ ì„±ëŠ¥ì„ ë³´ê°•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. |\n",
      "| **í”Œë«í¼ ë…ë¦½ì„±** | Windows, macOS, Linux, Android, iOS ë“± ê±°ì˜ ëª¨ë“  ìš´ì˜ì²´ì œì—ì„œ ë™ì¼í•˜ê²Œ ì‹¤í–‰ë©ë‹ˆë‹¤. |\n",
      "| **ì˜¤í”ˆì†ŒìŠ¤** | Python Software Foundation(PSF)ì´ ê´€ë¦¬í•˜ë©°, ì „ ì„¸ê³„ ì»¤ë®¤ë‹ˆí‹°ê°€ í™œë°œíˆ ê¸°ì—¬í•©ë‹ˆë‹¤. |\n",
      "| **ê´‘ë²”ìœ„í•œ ìƒíƒœê³„** | ì›¹, ë°ì´í„° ê³¼í•™, ì¸ê³µì§€ëŠ¥, ìë™í™”, ì„ë² ë””ë“œ, ê²Œì„ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì— íŠ¹í™”ëœ ì„œë“œíŒŒí‹° íŒ¨í‚¤ì§€ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. íŒŒì´ì¬ì´ ì“°ì´ëŠ” ë¶„ì•¼\n",
      "\n",
      "| ë¶„ì•¼ | ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬/í”„ë ˆì„ì›Œí¬ | í™œìš© ì˜ˆì‹œ |\n",
      "|------|--------------------------|----------|\n",
      "| **ì›¹ ê°œë°œ** | Django, Flask, FastAPI | ì›¹ ì„œë¹„ìŠ¤Â·API ì„œë²„ êµ¬ì¶• |\n",
      "| **ë°ì´í„° ê³¼í•™** | NumPy, pandas, SciPy | ë°ì´í„° ì „ì²˜ë¦¬Â·í†µê³„ ë¶„ì„ |\n",
      "| **ë¨¸ì‹ ëŸ¬ë‹Â·ë”¥ëŸ¬ë‹** | scikitâ€‘learn, TensorFlow, PyTorch | ëª¨ë¸ í•™ìŠµÂ·ì˜ˆì¸¡ |\n",
      "| **ìë™í™”Â·ìŠ¤í¬ë¦½íŠ¸** | ê¸°ë³¸ `os`, `subprocess`, `shutil` | íŒŒì¼Â·ì‹œìŠ¤í…œ ê´€ë¦¬, ë°°ì¹˜ ì‘ì—… |\n",
      "| **í´ë¼ìš°ë“œÂ·ì¸í”„ë¼** | Boto3(AWS), googleâ€‘cloudâ€‘storage | í´ë¼ìš°ë“œ ë¦¬ì†ŒìŠ¤ ì œì–´ |\n",
      "| **ê²Œì„ ê°œë°œ** | Pygame, Panda3D | 2D/3D ê²Œì„ í”„ë¡œí† íƒ€ì… |\n",
      "| **ê³¼í•™Â·ê³µí•™** | Matplotlib, Plotly, SymPy | ì‹œê°í™”Â·ìˆ˜ì‹ ì²˜ë¦¬ |\n",
      "| **ì„ë² ë””ë“œÂ·IoT** | MicroPython, CircuitPython | ë§ˆì´í¬ë¡œì»¨íŠ¸ë¡¤ëŸ¬ í”„ë¡œê·¸ë˜ë° |\n",
      "| **êµìœ¡** | Jupyter Notebook, REPL | ì¸í„°ë™í‹°ë¸Œ í•™ìŠµ í™˜ê²½ |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. íŒŒì´ì¬ ë¬¸ë²• í•µì‹¬ ì˜ˆì‹œ\n",
      "\n",
      "```python\n",
      "# 1ï¸âƒ£ ë³€ìˆ˜ì™€ ê¸°ë³¸ ìë£Œí˜•\n",
      "name = \"Alice\"\n",
      "age = 30\n",
      "height = 1.68\n",
      "is_student = False\n",
      "\n",
      "# 2ï¸âƒ£ ë¦¬ìŠ¤íŠ¸ì™€ ë”•ì…”ë„ˆë¦¬\n",
      "fruits = [\"apple\", \"banana\", \"cherry\"]\n",
      "person = {\"name\": \"Bob\", \"age\": 25, \"city\": \"Seoul\"}\n",
      "\n",
      "# 3ï¸âƒ£ í•¨ìˆ˜ ì •ì˜ (ë™ì  íƒ€ì´í•‘ + ê¸°ë³¸ê°’)\n",
      "def greet(name: str = \"Guest\") -> None:\n",
      "    print(f\"Hello, {name}!\")\n",
      "\n",
      "greet()               # Hello, Guest!\n",
      "greet(\"Charlie\")      # Hello, Charlie!\n",
      "\n",
      "# 4ï¸âƒ£ í´ë˜ìŠ¤ì™€ ê°ì²´ì§€í–¥\n",
      "class Animal:\n",
      "    def __init__(self, species: str):\n",
      "        self.species = species\n",
      "    \n",
      "    def speak(self):\n",
      "        raise NotImplementedError\n",
      "\n",
      "class Dog(Animal):\n",
      "    def speak(self):\n",
      "        return \"Woof!\"\n",
      "\n",
      "dog = Dog(\"Canine\")\n",
      "print(dog.speak())    # Woof!\n",
      "\n",
      "# 5ï¸âƒ£ ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ (í•¨ìˆ˜í˜• ìŠ¤íƒ€ì¼)\n",
      "squares = [x**2 for x in range(1, 6)]   # [1, 4, 9, 16, 25]\n",
      "\n",
      "# 6ï¸âƒ£ ì˜ˆì™¸ ì²˜ë¦¬\n",
      "try:\n",
      "    result = 10 / 0\n",
      "except ZeroDivisionError as e:\n",
      "    print(\"Cannot divide by zero!\", e)\n",
      "\n",
      "# 7ï¸âƒ£ íŒŒì¼ ì…ì¶œë ¥ (with êµ¬ë¬¸ ì‚¬ìš© ê¶Œì¥)\n",
      "with open(\"example.txt\", \"w\", encoding=\"utf-8\") as f:\n",
      "    f.write(\"íŒŒì´ì¬ì€ ì¬ë¯¸ìˆì–´ìš”!\\n\")\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## 4. íŒŒì´ì¬ ì‹¤í–‰ ë°©ë²•\n",
      "\n",
      "1. **ì„¤ì¹˜**  \n",
      "   - ê³µì‹ ì›¹ì‚¬ì´íŠ¸ <https://python.org> ì—ì„œ ìµœì‹  ë²„ì „(í˜„ì¬ 3.12.x ê¸°ì¤€) ë‹¤ìš´ë¡œë“œ.  \n",
      "   - Windows: ì„¤ì¹˜ ì‹œ *Add Python to PATH* ì˜µì…˜ ì²´í¬.  \n",
      "   - macOS/Linux: `brew install python` (macOS), `apt-get install python3` (Ubuntu) ë“± íŒ¨í‚¤ì§€ ë§¤ë‹ˆì € ì´ìš©.\n",
      "\n",
      "2. **ëŒ€í™”í˜• ì¸í„°í”„ë¦¬í„° (REPL)**  \n",
      "   ```bash\n",
      "   $ python3\n",
      "   >>> print(\"Hello, world!\")\n",
      "   Hello, world!\n",
      "   ```\n",
      "\n",
      "3. **ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰**  \n",
      "   ```bash\n",
      "   $ python3 my_script.py\n",
      "   ```\n",
      "\n",
      "4. **ê°€ìƒ í™˜ê²½(Virtual Environment)**  \n",
      "   í”„ë¡œì íŠ¸ë§ˆë‹¤ ë…ë¦½ëœ íŒ¨í‚¤ì§€ ì§‘í•©ì„ ê´€ë¦¬í•˜ë ¤ë©´:\n",
      "   ```bash\n",
      "   $ python3 -m venv venv          # ê°€ìƒ í™˜ê²½ ìƒì„±\n",
      "   $ source venv/bin/activate      # (Linux/macOS)\n",
      "   > venv\\Scripts\\activate.bat     # (Windows)\n",
      "   (venv) $ pip install requests   # íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
      "   ```\n",
      "\n",
      "5. **íŒ¨í‚¤ì§€ ê´€ë¦¬**  \n",
      "   - `pip` : ê¸°ë³¸ íŒ¨í‚¤ì§€ ë§¤ë‹ˆì € (`pip install numpy`).  \n",
      "   - `conda` : ê³¼í•™Â·ë°ì´í„° ë¶„ì•¼ì—ì„œ ë§ì´ ì‚¬ìš©ë˜ëŠ” í™˜ê²½Â·íŒ¨í‚¤ì§€ ê´€ë¦¬ ë„êµ¬.\n",
      "\n",
      "---\n",
      "\n",
      "## 5. íŒŒì´ì¬ ì„±ëŠ¥ê³¼ ìµœì í™”\n",
      "\n",
      "| ê´€ì  | ë‚´ìš© |\n",
      "|------|------|\n",
      "| **ì¸í„°í”„ë¦¬í„°** | CPython(ê°€ì¥ ë³´í¸ì ì¸ êµ¬í˜„)ì€ Cë¡œ ì‘ì„±ë˜ì–´ ì•ˆì •ì ì´ì§€ë§Œ, ìˆœìˆ˜ íŒŒì´ì¬ ì½”ë“œì˜ ì‹¤í–‰ ì†ë„ëŠ” C/Java ëŒ€ë¹„ ëŠë¦½ë‹ˆë‹¤. |\n",
      "| **JIT êµ¬í˜„** | PyPy(Justâ€‘Inâ€‘Time ì»´íŒŒì¼) ì‚¬ìš© ì‹œ ë™ì¼ ì½”ë“œê°€ 2~5ë°° ë¹ ë¥´ê²Œ ì‹¤í–‰ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. |\n",
      "| **C í™•ì¥** | `numpy`, `pandas`ì™€ ê°™ì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ë‚´ë¶€ì ìœ¼ë¡œ C/Fortran ì½”ë“œë¥¼ ì‚¬ìš©í•´ ì—°ì‚° ì†ë„ë¥¼ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤. |\n",
      "| **ë©€í‹°ìŠ¤ë ˆë”©** | GIL(Global Interpreter Lock) ë•Œë¬¸ì— CPU ë°”ìš´ë“œ ì‘ì—…ì€ ìŠ¤ë ˆë“œë³´ë‹¤ `multiprocessing`ì´ë‚˜ `concurrent.futures.ProcessPoolExecutor` ì‚¬ìš©ì´ ê¶Œì¥ë©ë‹ˆë‹¤. |\n",
      "| **ë¹„ë™ê¸° I/O** | `asyncio`, `trio`, `anyio` ë“±ì„ ì´ìš©í•´ I/Oâ€‘bound ì‘ì—…ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. |\n",
      "| **í”„ë¡œíŒŒì¼ë§** | `cProfile`, `line_profiler`, `memory_profiler` ë“±ìœ¼ë¡œ ë³‘ëª©ì„ ì°¾ì•„ ìµœì í™”í•©ë‹ˆë‹¤. |\n",
      "\n",
      "---\n",
      "\n",
      "## 6. íŒŒì´ì¬ í•™ìŠµ ë¡œë“œë§µ (ì´ˆê¸‰ â†’ ê³ ê¸‰)\n",
      "\n",
      "1. **ê¸°ì´ˆ**  \n",
      "   - ë³€ìˆ˜Â·ìë£Œí˜•Â·ì—°ì‚°ì  \n",
      "   - ì œì–´ë¬¸(if, for, while)  \n",
      "   - í•¨ìˆ˜Â·ìŠ¤ì½”í”„Â·ì˜ˆì™¸ ì²˜ë¦¬  \n",
      "\n",
      "2. **ë°ì´í„° êµ¬ì¡°**  \n",
      "   - ë¦¬ìŠ¤íŠ¸, íŠœí”Œ, ë”•ì…”ë„ˆë¦¬, ì§‘í•©  \n",
      "   - ë¦¬ìŠ¤íŠ¸Â·ë”•ì…”ë„ˆë¦¬ ì»´í”„ë¦¬í—¨ì…˜  \n",
      "\n",
      "3. **íŒŒì¼Â·ì…ì¶œë ¥**  \n",
      "   - í…ìŠ¤íŠ¸Â·ë°”ì´ë„ˆë¦¬ íŒŒì¼  \n",
      "   - CSVÂ·JSONÂ·XML íŒŒì‹±  \n",
      "\n",
      "4. **ê°ì²´ì§€í–¥**  \n",
      "   - í´ë˜ìŠ¤Â·ìƒì†Â·ë‹¤í˜•ì„±Â·ë©”íƒ€í´ë˜ìŠ¤  \n",
      "\n",
      "5. **í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©**  \n",
      "   - `datetime`, `os`, `sys`, `subprocess`, `logging`  \n",
      "\n",
      "6. **ê°€ìƒ í™˜ê²½Â·íŒ¨í‚¤ì§€ ê´€ë¦¬**  \n",
      "   - `venv`, `pip`, `requirements.txt`  \n",
      "\n",
      "7. **í”„ë ˆì„ì›Œí¬Â·ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„ íƒ**  \n",
      "   - ì›¹: Flask/Django/FastAPI  \n",
      "   - ë°ì´í„°: pandas, NumPy, Matplotlib  \n",
      "   - ë¨¸ì‹ ëŸ¬ë‹: scikitâ€‘learn, TensorFlow, PyTorch  \n",
      "\n",
      "8. **í…ŒìŠ¤íŠ¸Â·CI**  \n",
      "   - `unittest`, `pytest`  \n",
      "   - GitHub Actions, GitLab CI  \n",
      "\n",
      "9. **ë°°í¬Â·ìš´ì˜**  \n",
      "   - Docker, Kubernetes, ì„œë²„ë¦¬ìŠ¤(AWS Lambda)  \n",
      "   - `pyinstaller`(ì‹¤í–‰ íŒŒì¼ ìƒì„±)  \n",
      "\n",
      "---\n",
      "\n",
      "## 7. íŒŒì´ì¬ ì»¤ë®¤ë‹ˆí‹°ì™€ ìë£Œ\n",
      "\n",
      "| ì¢…ë¥˜ | URL | íŠ¹ì§• |\n",
      "|------|-----|------|\n",
      "| **ê³µì‹ ë¬¸ì„œ** | <https://docs.python.org/3/> | ìµœì‹  ìŠ¤í™Â·ì˜ˆì œ |\n",
      "| **íŒ¨í‚¤ì§€ ì¸ë±ìŠ¤** | <https://pypi.org/> | 300k+ ì„œë“œíŒŒí‹° íŒ¨í‚¤ì§€ |\n",
      "| **íŠœí† ë¦¬ì–¼** | <https://realpython.com/> | ì‹¤ë¬´ ì¤‘ì‹¬ ê°€ì´ë“œ |\n",
      "| **Q&A** | <https://stackoverflow.com/questions/tagged/python> | ë¬¸ì œ í•´ê²°ì— ìµœì  |\n",
      "| **ì»¤ë®¤ë‹ˆí‹°** | Reddit r/Python, Discord, Slack | í† ë¡ Â·ì •ë³´ ê³µìœ  |\n",
      "| **í•™ìŠµ í”Œë«í¼** | Coursera, edX, Udemy, Fast.ai | ë‹¨ê³„ë³„ ê°•ì˜ |\n",
      "\n",
      "---\n",
      "\n",
      "## 8. ê²°ë¡ \n",
      "\n",
      "- **íŒŒì´ì¬ì€ â€œì½ê¸° ì‰¬ìš´ ì½”ë“œ + í’ë¶€í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬â€** ë¼ëŠ” ì¡°í•© ë•ë¶„ì— **ì‹œì‘ì´ ì‰½ê³ ** **ì‹¤ì œ í”„ë¡œì íŠ¸ì— ë°”ë¡œ ì ìš©** í•  ìˆ˜ ìˆëŠ” ì–¸ì–´ì…ë‹ˆë‹¤.\n",
      "- **ë°ì´í„° ê³¼í•™Â·AI** ë¶„ì•¼ì—ì„œëŠ” ì‚¬ì‹¤ìƒ í‘œì¤€ì´ ë˜ì—ˆìœ¼ë©°, **ì›¹Â·ìë™í™”Â·ì‹œìŠ¤í…œ ê´€ë¦¬** ë“±ì—ì„œë„ ê°•ë ¥í•œ ì…ì§€ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "- **ì„±ëŠ¥**ì´ ì¤‘ìš”í•œ ê²½ìš° C í™•ì¥, PyPy, ë©€í‹°í”„ë¡œì„¸ì‹± ë“±ì„ ì ì ˆíˆ í™œìš©í•˜ë©´ ì¶©ë¶„íˆ ë³´ì™„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "- í™œë°œí•œ **ì˜¤í”ˆì†ŒìŠ¤ ì»¤ë®¤ë‹ˆí‹°**ì™€ **ê´‘ë²”ìœ„í•œ ìƒíƒœê³„** ë•ë¶„ì— ìƒˆë¡œìš´ ê¸°ìˆ ì„ ë°°ìš°ê±°ë‚˜ ë¬¸ì œë¥¼ í•´ê²°í•  ë•Œ ì–¸ì œë“ ì§€ ë„ì›€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "> **í•œ ì¤„ ìš”ì•½**: íŒŒì´ì¬ì€ **ì½ê¸° ì‰¬ìš´ ë¬¸ë²•**ê³¼ **ë‹¤ì–‘í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬**ë¥¼ ê°–ì¶˜ **ë²”ìš© í”„ë¡œê·¸ë˜ë° ì–¸ì–´**ì´ë©°, ì´ˆë³´ìë¶€í„° ì „ë¬¸ê°€ê¹Œì§€ í­ë„“ê²Œ í™œìš©í•  ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ ë„êµ¬ì…ë‹ˆë‹¤. \n",
      "\n",
      "ê¶ê¸ˆí•œ ì ì´ ë” ìˆìœ¼ë©´ ì–¸ì œë“  ì§ˆë¬¸í•´ì£¼ì„¸ìš”! ğŸš€\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(type(response))\n",
    "    print(\"ì‘ë‹µ:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001E1163E98B0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001E1163EA300>, root_client=<openai.OpenAI object at 0x000001E1163E99A0>, root_async_client=<openai.AsyncOpenAI object at 0x000001E1163E9CA0>, model_name='openai/gpt-oss-120b', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"input\":\"LangChainì€ ë¬´ì—‡ì¸ê°€ìš”\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "## LangChainì´ë€?\n",
      "\n",
      "**LangChain**ì€ **ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)**ì„ **ì• í”Œë¦¬ì¼€ì´ì…˜ ìˆ˜ì¤€**ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ëŠ” **ì˜¤í”ˆì†ŒìŠ¤ í”„ë ˆì„ì›Œí¬**ì…ë‹ˆë‹¤.  \n",
      "LLMì„ ë‹¨ìˆœíˆ â€œí”„ë¡¬í”„íŠ¸ â†’ ë‹µë³€â€ í˜•íƒœë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, **ë°ì´í„°ë² ì´ìŠ¤, ê²€ìƒ‰ ì—”ì§„, íˆ´, ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤** ë“± ë‹¤ì–‘í•œ ì™¸ë¶€ ì‹œìŠ¤í…œê³¼ **ì—°ê²°í•˜ê³ ** **ë³µí•©ì ì¸ ì›Œí¬í”Œë¡œìš°**ë¥¼ êµ¬ì„±í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## í•µì‹¬ ëª©í‘œ\n",
      "\n",
      "| ëª©í‘œ | ì„¤ëª… |\n",
      "|------|------|\n",
      "| **ëª¨ë“ˆí™”** | LLM, í”„ë¡¬í”„íŠ¸, ë©”ëª¨ë¦¬, ì²´ì¸, ì—ì´ì „íŠ¸ ë“±ì„ ë…ë¦½ì ì¸ ì»´í¬ë„ŒíŠ¸ë¡œ ì œê³µ â†’ í•„ìš”ì— ë”°ë¼ ì¡°í•©Â·êµì²´ ê°€ëŠ¥ |\n",
      "| **í™•ì¥ì„±** | ì—¬ëŸ¬ LLM(OpenAI, Anthropic, Cohere, Llama, Azure ë“±)ê³¼ ë°±ì—”ë“œ(ë²¡í„° DB, ê²€ìƒ‰ API, ë„êµ¬)ì™€ ì‰½ê²Œ ì—°ê²° |\n",
      "| **ìƒì‚°ì„±** | ë³µì¡í•œ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§Â·ì²´ì¸ ì„¤ê³„ ì‘ì—…ì„ ì¶”ìƒí™”í•´, ìµœì†Œ ì½”ë“œë¡œ ê³ ê¸‰ ê¸°ëŠ¥ êµ¬í˜„ |\n",
      "| **í‘œì¤€í™”** | ë‹¤ì–‘í•œ LLM ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜(ì±—ë´‡, RAG, ìë™í™” ì—ì´ì „íŠ¸ ë“±)ì—ì„œ ê³µí†µìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì¸í„°í˜ì´ìŠ¤ ì œê³µ |\n",
      "\n",
      "---\n",
      "\n",
      "## ì£¼ìš” êµ¬ì„± ìš”ì†Œ\n",
      "\n",
      "| êµ¬ì„± ìš”ì†Œ | ì—­í•  | ì£¼ìš” í´ë˜ìŠ¤/í•¨ìˆ˜ |\n",
      "|-----------|------|-----------------|\n",
      "| **LLM ë˜í¼** | OpenAI, Anthropic, Llama ë“± ì‹¤ì œ ëª¨ë¸ í˜¸ì¶œì„ ì¶”ìƒí™” | `OpenAI`, `ChatOpenAI`, `Anthropic`, `Cohere`, `LlamaCPP` |\n",
      "| **í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿** | ë³€ìˆ˜ ì‚½ì…, ì²´ì¸ ì—°ê²° ì‹œ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸ ì •ì˜ | `PromptTemplate`, `ChatPromptTemplate` |\n",
      "| **ì²´ì¸(Chain)** | ì—¬ëŸ¬ LLM í˜¸ì¶œÂ·í”„ë¡¬í”„íŠ¸Â·íˆ´ì„ ìˆœì°¨Â·ì¡°ê±´ë¶€ë¡œ ì—°ê²° | `LLMChain`, `SequentialChain`, `SimpleSequentialChain` |\n",
      "| **ì—ì´ì „íŠ¸(Agent)** | â€œë„êµ¬ë¥¼ ì‚¬ìš©í•´ ëª©í‘œ ë‹¬ì„±â€ì„ ìë™ìœ¼ë¡œ ê³„íšÂ·ì‹¤í–‰ (ì˜ˆ: ì›¹ ê²€ìƒ‰, ì½”ë“œ ì‹¤í–‰) | `AgentExecutor`, `Tool`, `ZeroShotAgent`, `ConversationalAgent` |\n",
      "| **ë©”ëª¨ë¦¬(Memory)** | ëŒ€í™” ì´ë ¥Â·ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ ì§€í•´ ìƒíƒœful ëŒ€í™” êµ¬í˜„ | `ConversationBufferMemory`, `ConversationSummaryMemory` |\n",
      "| **ë²¡í„° ìŠ¤í† ì–´ & ê²€ìƒ‰** | ë¬¸ì„œ ì„ë² ë”© â†’ ìœ ì‚¬ë„ ê²€ìƒ‰ â†’ RAG (Retrievalâ€‘Augmented Generation) | `FAISS`, `Pinecone`, `Weaviate`, `Chroma`, `Milvus` |\n",
      "| **íˆ´(Tool)** | LLMì´ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” ì™¸ë¶€ ê¸°ëŠ¥ (ê²€ìƒ‰, ê³„ì‚°, API í˜¸ì¶œ ë“±) | `SerpAPIWrapper`, `RequestsGetTool`, `PythonREPLTool` |\n",
      "| **ì½œë°±Â·ë¡œê¹…** | ì‹¤í–‰ íë¦„, í† í° ì‚¬ìš©ëŸ‰, ì—ëŸ¬ ë“±ì„ ì‹¤ì‹œê°„ ê°ì‹œ | `CallbackManager`, `StdOutCallbackHandler` |\n",
      "\n",
      "---\n",
      "\n",
      "## ëŒ€í‘œì ì¸ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤\n",
      "\n",
      "| ì‹œë‚˜ë¦¬ì˜¤ | êµ¬í˜„ íë¦„ (ì˜ˆì‹œ) |\n",
      "|----------|-------------------|\n",
      "| **Q&A ì±—ë´‡** | `ChatOpenAI` + `ConversationBufferMemory` â†’ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ê¸°ì–µí•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ëŠ” ëŒ€í™” |\n",
      "| **RAG (Retrievalâ€‘Augmented Generation)** | ë¬¸ì„œ â†’ `Embedding` â†’ `FAISS` ë²¡í„° ìŠ¤í† ì–´ â†’ ì§ˆì˜ â†’ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ 3ê°œ ì¶”ì¶œ â†’ `LLMChain`ì— í”„ë¡¬í”„íŠ¸ë¡œ ì „ë‹¬ â†’ ë‹µë³€ ìƒì„± |\n",
      "| **ìë™í™” ì—ì´ì „íŠ¸** | ëª©í‘œ(ì˜ˆ: â€œë‚ ì”¨ì™€ ì£¼ì‹ ì •ë³´ë¥¼ ì•Œë ¤ì¤˜â€) â†’ `ZeroShotAgent`ê°€ `SerpAPI`ì™€ `AlphaVantage` ê°™ì€ íˆ´ì„ ìˆœì°¨ì ìœ¼ë¡œ í˜¸ì¶œ â†’ ê²°ê³¼ ì¢…í•© í›„ ì‚¬ìš©ìì—ê²Œ ì „ë‹¬ |\n",
      "| **ì½”ë“œ ìƒì„±Â·ì‹¤í–‰** | `ChatOpenAI` â†’ `PythonREPLTool` (ì½”ë“œ ì‹¤í–‰) â†’ ì‹¤í–‰ ê²°ê³¼ë¥¼ í”„ë¡¬í”„íŠ¸ì— ë°˜ì˜ â†’ ë°˜ë³µì ì¸ ë””ë²„ê¹…/ê°œì„  |\n",
      "| **ë©€í‹°ëª¨ë‹¬ íŒŒì´í”„ë¼ì¸** | ì´ë¯¸ì§€ â†’ `CLIP` ì„ë² ë”© â†’ í…ìŠ¤íŠ¸ì™€ ê²°í•© â†’ `LLMChain`ì— ì „ë‹¬ â†’ ì´ë¯¸ì§€ ì„¤ëª…Â·ì§ˆë¬¸ ë‹µë³€ |\n",
      "\n",
      "---\n",
      "\n",
      "## ê°„ë‹¨í•œ ì½”ë“œ ì˜ˆì‹œ (Python)\n",
      "\n",
      "ì•„ë˜ëŠ” **FAISS ê¸°ë°˜ RAG** íŒŒì´í”„ë¼ì¸ì„ 30ì¤„ ë‚´ì™¸ë¡œ êµ¬í˜„í•œ ì˜ˆì‹œì…ë‹ˆë‹¤.\n",
      "\n",
      "```python\n",
      "from langchain.embeddings import OpenAIEmbeddings\n",
      "from langchain.vectorstores import FAISS\n",
      "from langchain.llms import OpenAI\n",
      "from langchain.chains import RetrievalQA\n",
      "from langchain.prompts import PromptTemplate\n",
      "\n",
      "# 1ï¸âƒ£ ë¬¸ì„œ ë¡œë“œ & ì„ë² ë”©\n",
      "docs = [\"LangChainì€ LLMì„ ì• í”Œë¦¬ì¼€ì´ì…˜ ìˆ˜ì¤€ìœ¼ë¡œ ì—°ê²°í•˜ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\",\n",
      "        \"ë²¡í„° DBì™€ ì—°ë™í•´ RAGë¥¼ ì†ì‰½ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"]\n",
      "embeddings = OpenAIEmbeddings()\n",
      "vectorstore = FAISS.from_texts(docs, embeddings)\n",
      "\n",
      "# 2ï¸âƒ£ Retrieval QA ì²´ì¸ ì •ì˜\n",
      "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
      "prompt = PromptTemplate(\n",
      "    input_variables=[\"context\", \"question\"],\n",
      "    template=\"ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•´ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.\\në¬¸ì„œ: {context}\\nì§ˆë¬¸: {question}\"\n",
      ")\n",
      "qa_chain = RetrievalQA.from_chain_type(\n",
      "    llm=OpenAI(),\n",
      "    retriever=retriever,\n",
      "    chain_type=\"stuff\",\n",
      "    return_source_documents=True,\n",
      "    prompt=prompt,\n",
      ")\n",
      "\n",
      "# 3ï¸âƒ£ ì§ˆë¬¸ ì‹¤í–‰\n",
      "query = \"LangChainì„ ì‚¬ìš©í•˜ë©´ ì–´ë–¤ ì¥ì ì´ ìˆë‚˜ìš”?\"\n",
      "result = qa_chain({\"query\": query})\n",
      "\n",
      "print(\"ë‹µë³€:\", result[\"result\"])\n",
      "print(\"\\nì°¸ì¡° ë¬¸ì„œ:\", [doc.page_content for doc in result[\"source_documents\"]])\n",
      "```\n",
      "\n",
      "**í•µì‹¬ í¬ì¸íŠ¸**\n",
      "\n",
      "1. `OpenAIEmbeddings` â†’ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°í™”  \n",
      "2. `FAISS` â†’ ë¡œì»¬ ë©”ëª¨ë¦¬ ë²¡í„° DB (ë‹¤ë¥¸ DBë¡œ êµì²´ ê°€ëŠ¥)  \n",
      "3. `RetrievalQA` â†’ ê²€ìƒ‰â€‘ì‘ë‹µ ì²´ì¸, `prompt` ë¡œ ë‹µë³€ í˜•ì‹ ì§€ì •  \n",
      "4. `return_source_documents=True` ë¡œ ê·¼ê±° ë¬¸ì„œë„ í•¨ê»˜ ë°˜í™˜\n",
      "\n",
      "---\n",
      "\n",
      "## ì™œ LangChainì„ ì„ íƒí•´ì•¼ í• ê¹Œ?\n",
      "\n",
      "| ì¥ì  | ìƒì„¸ ì„¤ëª… |\n",
      "|------|-----------|\n",
      "| **ë‹¤ì–‘í•œ LLM ì§€ì›** | OpenAI, Anthropic, Cohere, Llama ë“± ìµœì‹  ëª¨ë¸ì„ ì†ì‰½ê²Œ êµì²´ |\n",
      "| **í”ŒëŸ¬ê·¸ì¸Â·íˆ´ ìƒíƒœê³„** | ê²€ìƒ‰, ë°ì´í„°ë² ì´ìŠ¤, ì½”ë“œ ì‹¤í–‰, íŒŒì¼ ì‹œìŠ¤í…œ ë“± ìˆ˜ë°± ê°œ íˆ´ì´ ë¯¸ë¦¬ êµ¬í˜„ë¼ ìˆìŒ |\n",
      "| **ìœ ì—°í•œ íŒŒì´í”„ë¼ì¸** | ë‹¨ìˆœ ì²´ì¸ë¶€í„° ë³µì¡í•œ ì—ì´ì „íŠ¸ê¹Œì§€ ë‹¨ê³„ë³„ë¡œ í™•ì¥ ê°€ëŠ¥ |\n",
      "| **ì»¤ë®¤ë‹ˆí‹°Â·ìƒíƒœê³„** | GitHub â˜… 30k+, í™œë°œí•œ í¬ëŸ¼Â·Discord, ê³µì‹ ë¬¸ì„œÂ·í…œí”Œë¦¿ í’ë¶€ |\n",
      "| **ì–¸ì–´Â·í”„ë ˆì„ì›Œí¬ ë…ë¦½** | Pythonì´ ê¸°ë³¸ì´ì§€ë§Œ, JavaScript/TS, Java, Go ë“± ë‹¤ë¥¸ ì–¸ì–´ìš© ë˜í¼ë„ ì ì°¨ í™•ëŒ€ ì¤‘ |\n",
      "\n",
      "---\n",
      "\n",
      "## ì‹œì‘í•˜ê¸°\n",
      "\n",
      "1. **ì„¤ì¹˜**  \n",
      "   ```bash\n",
      "   pip install langchain openai   # ê¸°ë³¸ íŒ¨í‚¤ì§€\n",
      "   # í•„ìš”ì— ë”°ë¼ FAISS, pinecone, chromadb ë“± ì¶”ê°€ ì„¤ì¹˜\n",
      "   ```\n",
      "\n",
      "2. **API í‚¤ ì„¤ì •** (OpenAI ì˜ˆì‹œ)  \n",
      "   ```bash\n",
      "   export OPENAI_API_KEY=\"sk-...\"\n",
      "   ```\n",
      "\n",
      "3. **ì²« ë²ˆì§¸ ì²´ì¸ ì‹¤í–‰** (ìœ„ ì˜ˆì‹œì™€ ê°™ì´ ê°„ë‹¨íˆ êµ¬í˜„)\n",
      "\n",
      "4. **ê³µì‹ ë¬¸ì„œ** â†’ <https://python.langchain.com/>  \n",
      "   **GitHub** â†’ <https://github.com/langchain-ai/langchain>\n",
      "\n",
      "---\n",
      "\n",
      "## ë§ˆë¬´ë¦¬\n",
      "\n",
      "- **LangChain**ì€ â€œLLM + ì™¸ë¶€ ì‹œìŠ¤í…œ = ì‹¤ì œ ì„œë¹„ìŠ¤â€ ë¼ëŠ” ëª©í‘œë¥¼ ì‹¤í˜„í•˜ê¸° ìœ„í•œ **ëª¨ë“ˆí˜• íˆ´í‚·**ì…ë‹ˆë‹¤.  \n",
      "- í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì— ë¨¸ë¬´ë¥´ì§€ ì•Šê³  **ê²€ìƒ‰, ë©”ëª¨ë¦¬, íˆ´, ì—ì´ì „íŠ¸** ë“±ì„ ê²°í•©í•´ **ë³µí•©ì ì¸ AI ì• í”Œë¦¬ì¼€ì´ì…˜**ì„ ë¹ ë¥´ê²Œ í”„ë¡œí† íƒ€ì´í•‘Â·ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
      "- Python ê¸°ë°˜ì´ ê°€ì¥ ì„±ìˆ™í•˜ì§€ë§Œ, ë‹¤ë¥¸ ì–¸ì–´ì—ì„œë„ ì ì°¨ ì§€ì›ì´ í™•ëŒ€ë˜ê³  ìˆì–´ **ë©€í‹°í”Œë«í¼** AI ê°œë°œì— ìœ ìš©í•©ë‹ˆë‹¤.\n",
      "\n",
      "ê¶ê¸ˆí•œ ì ì´ë‚˜ êµ¬ì²´ì ì¸ êµ¬í˜„ ì‚¬ë¡€ê°€ í•„ìš”í•˜ë©´ ì–¸ì œë“  ì§ˆë¬¸í•´ì£¼ì„¸ìš”! ğŸš€\n"
     ]
    }
   ],
   "source": [
    "print(type(response))\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
