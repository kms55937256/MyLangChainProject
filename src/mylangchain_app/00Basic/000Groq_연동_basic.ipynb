{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain!!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello LangChain!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_w\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "#load_dotenv(dotenv_path='.env')\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.chat.ChatPromptTemplate'>\n",
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt + llm + output \n",
    "\n",
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"당신은 개발자입니다.\") , \n",
    "     (\"user\", \"{input}\") ]\n",
    ")\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "System: 당신은 개발자입니다.\n",
      "Human: 파이썬은 무엇인가요? 자세하게 설명해주세요\n"
     ]
    }
   ],
   "source": [
    "prompt_text = prompt.format(input=\"파이썬은 무엇인가요? 자세하게 설명해주세요\")\n",
    "print(type(prompt_text))\n",
    "print(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_openai.chat_models.base.ChatOpenAI'>\n",
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001E1163E98B0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001E1163EA300> root_client=<openai.OpenAI object at 0x000001E1163E99A0> root_async_client=<openai.AsyncOpenAI object at 0x000001E1163E9CA0> model_name='openai/gpt-oss-120b' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "#llm = ChatOpenAI(api_key=OPENAI_API_KEY, model_name=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# Groq API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    #model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(type(llm))\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "응답: ## 파이썬(Python)이란?\n",
      "\n",
      "파이썬은 **고수준(high‑level), 인터프리터(interpreted), 동적 타이핑(dynamic typing)** 언어이며, **범용 프로그래밍 언어(general‑purpose)** 로 설계되었습니다. 1991년 네덜란드의 귀도 반 로섬(Guido van Rossum)이 처음 발표했으며, 현재는 전 세계 수많은 개발자와 기업이 사용하고 있는 가장 인기 있는 언어 중 하나입니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. 파이썬의 주요 특징\n",
      "\n",
      "| 특징 | 설명 |\n",
      "|------|------|\n",
      "| **읽기 쉬운 문법** | 코드가 자연어에 가깝게 설계돼 초보자도 이해하기 쉽습니다. 들여쓰기(Indentation)만으로 블록을 구분합니다. |\n",
      "| **동적 타이핑** | 변수 선언 시 타입을 명시하지 않아도 런타임에 자동으로 결정됩니다. (`x = 10`, `x = \"hello\"` 가능) |\n",
      "| **인터프리터 언어** | 코드를 한 줄씩 실행해 바로 결과를 확인할 수 있어 빠른 프로토타이핑이 가능합니다. |\n",
      "| **멀티패러다임** | 절차적, 객체지향, 함수형 프로그래밍을 모두 지원합니다. |\n",
      "| **풍부한 표준 라이브러리** | 파일 입출력, 네트워킹, 데이터 직렬화, 웹 서버 등 2,000개 이상의 모듈이 기본 제공됩니다. |\n",
      "| **확장성** | C, C++, Rust 등으로 작성된 모듈을 쉽게 연결해 성능을 보강할 수 있습니다. |\n",
      "| **플랫폼 독립성** | Windows, macOS, Linux, Android, iOS 등 거의 모든 운영체제에서 동일하게 실행됩니다. |\n",
      "| **오픈소스** | Python Software Foundation(PSF)이 관리하며, 전 세계 커뮤니티가 활발히 기여합니다. |\n",
      "| **광범위한 생태계** | 웹, 데이터 과학, 인공지능, 자동화, 임베디드, 게임 등 다양한 분야에 특화된 서드파티 패키지가 존재합니다. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. 파이썬이 쓰이는 분야\n",
      "\n",
      "| 분야 | 주요 라이브러리/프레임워크 | 활용 예시 |\n",
      "|------|--------------------------|----------|\n",
      "| **웹 개발** | Django, Flask, FastAPI | 웹 서비스·API 서버 구축 |\n",
      "| **데이터 과학** | NumPy, pandas, SciPy | 데이터 전처리·통계 분석 |\n",
      "| **머신러닝·딥러닝** | scikit‑learn, TensorFlow, PyTorch | 모델 학습·예측 |\n",
      "| **자동화·스크립트** | 기본 `os`, `subprocess`, `shutil` | 파일·시스템 관리, 배치 작업 |\n",
      "| **클라우드·인프라** | Boto3(AWS), google‑cloud‑storage | 클라우드 리소스 제어 |\n",
      "| **게임 개발** | Pygame, Panda3D | 2D/3D 게임 프로토타입 |\n",
      "| **과학·공학** | Matplotlib, Plotly, SymPy | 시각화·수식 처리 |\n",
      "| **임베디드·IoT** | MicroPython, CircuitPython | 마이크로컨트롤러 프로그래밍 |\n",
      "| **교육** | Jupyter Notebook, REPL | 인터랙티브 학습 환경 |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. 파이썬 문법 핵심 예시\n",
      "\n",
      "```python\n",
      "# 1️⃣ 변수와 기본 자료형\n",
      "name = \"Alice\"\n",
      "age = 30\n",
      "height = 1.68\n",
      "is_student = False\n",
      "\n",
      "# 2️⃣ 리스트와 딕셔너리\n",
      "fruits = [\"apple\", \"banana\", \"cherry\"]\n",
      "person = {\"name\": \"Bob\", \"age\": 25, \"city\": \"Seoul\"}\n",
      "\n",
      "# 3️⃣ 함수 정의 (동적 타이핑 + 기본값)\n",
      "def greet(name: str = \"Guest\") -> None:\n",
      "    print(f\"Hello, {name}!\")\n",
      "\n",
      "greet()               # Hello, Guest!\n",
      "greet(\"Charlie\")      # Hello, Charlie!\n",
      "\n",
      "# 4️⃣ 클래스와 객체지향\n",
      "class Animal:\n",
      "    def __init__(self, species: str):\n",
      "        self.species = species\n",
      "    \n",
      "    def speak(self):\n",
      "        raise NotImplementedError\n",
      "\n",
      "class Dog(Animal):\n",
      "    def speak(self):\n",
      "        return \"Woof!\"\n",
      "\n",
      "dog = Dog(\"Canine\")\n",
      "print(dog.speak())    # Woof!\n",
      "\n",
      "# 5️⃣ 리스트 컴프리헨션 (함수형 스타일)\n",
      "squares = [x**2 for x in range(1, 6)]   # [1, 4, 9, 16, 25]\n",
      "\n",
      "# 6️⃣ 예외 처리\n",
      "try:\n",
      "    result = 10 / 0\n",
      "except ZeroDivisionError as e:\n",
      "    print(\"Cannot divide by zero!\", e)\n",
      "\n",
      "# 7️⃣ 파일 입출력 (with 구문 사용 권장)\n",
      "with open(\"example.txt\", \"w\", encoding=\"utf-8\") as f:\n",
      "    f.write(\"파이썬은 재미있어요!\\n\")\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## 4. 파이썬 실행 방법\n",
      "\n",
      "1. **설치**  \n",
      "   - 공식 웹사이트 <https://python.org> 에서 최신 버전(현재 3.12.x 기준) 다운로드.  \n",
      "   - Windows: 설치 시 *Add Python to PATH* 옵션 체크.  \n",
      "   - macOS/Linux: `brew install python` (macOS), `apt-get install python3` (Ubuntu) 등 패키지 매니저 이용.\n",
      "\n",
      "2. **대화형 인터프리터 (REPL)**  \n",
      "   ```bash\n",
      "   $ python3\n",
      "   >>> print(\"Hello, world!\")\n",
      "   Hello, world!\n",
      "   ```\n",
      "\n",
      "3. **스크립트 실행**  \n",
      "   ```bash\n",
      "   $ python3 my_script.py\n",
      "   ```\n",
      "\n",
      "4. **가상 환경(Virtual Environment)**  \n",
      "   프로젝트마다 독립된 패키지 집합을 관리하려면:\n",
      "   ```bash\n",
      "   $ python3 -m venv venv          # 가상 환경 생성\n",
      "   $ source venv/bin/activate      # (Linux/macOS)\n",
      "   > venv\\Scripts\\activate.bat     # (Windows)\n",
      "   (venv) $ pip install requests   # 패키지 설치\n",
      "   ```\n",
      "\n",
      "5. **패키지 관리**  \n",
      "   - `pip` : 기본 패키지 매니저 (`pip install numpy`).  \n",
      "   - `conda` : 과학·데이터 분야에서 많이 사용되는 환경·패키지 관리 도구.\n",
      "\n",
      "---\n",
      "\n",
      "## 5. 파이썬 성능과 최적화\n",
      "\n",
      "| 관점 | 내용 |\n",
      "|------|------|\n",
      "| **인터프리터** | CPython(가장 보편적인 구현)은 C로 작성되어 안정적이지만, 순수 파이썬 코드의 실행 속도는 C/Java 대비 느립니다. |\n",
      "| **JIT 구현** | PyPy(Just‑In‑Time 컴파일) 사용 시 동일 코드가 2~5배 빠르게 실행될 수 있습니다. |\n",
      "| **C 확장** | `numpy`, `pandas`와 같은 라이브러리는 내부적으로 C/Fortran 코드를 사용해 연산 속도를 크게 향상시킵니다. |\n",
      "| **멀티스레딩** | GIL(Global Interpreter Lock) 때문에 CPU 바운드 작업은 스레드보다 `multiprocessing`이나 `concurrent.futures.ProcessPoolExecutor` 사용이 권장됩니다. |\n",
      "| **비동기 I/O** | `asyncio`, `trio`, `anyio` 등을 이용해 I/O‑bound 작업을 효율적으로 처리할 수 있습니다. |\n",
      "| **프로파일링** | `cProfile`, `line_profiler`, `memory_profiler` 등으로 병목을 찾아 최적화합니다. |\n",
      "\n",
      "---\n",
      "\n",
      "## 6. 파이썬 학습 로드맵 (초급 → 고급)\n",
      "\n",
      "1. **기초**  \n",
      "   - 변수·자료형·연산자  \n",
      "   - 제어문(if, for, while)  \n",
      "   - 함수·스코프·예외 처리  \n",
      "\n",
      "2. **데이터 구조**  \n",
      "   - 리스트, 튜플, 딕셔너리, 집합  \n",
      "   - 리스트·딕셔너리 컴프리헨션  \n",
      "\n",
      "3. **파일·입출력**  \n",
      "   - 텍스트·바이너리 파일  \n",
      "   - CSV·JSON·XML 파싱  \n",
      "\n",
      "4. **객체지향**  \n",
      "   - 클래스·상속·다형성·메타클래스  \n",
      "\n",
      "5. **표준 라이브러리 활용**  \n",
      "   - `datetime`, `os`, `sys`, `subprocess`, `logging`  \n",
      "\n",
      "6. **가상 환경·패키지 관리**  \n",
      "   - `venv`, `pip`, `requirements.txt`  \n",
      "\n",
      "7. **프레임워크·라이브러리 선택**  \n",
      "   - 웹: Flask/Django/FastAPI  \n",
      "   - 데이터: pandas, NumPy, Matplotlib  \n",
      "   - 머신러닝: scikit‑learn, TensorFlow, PyTorch  \n",
      "\n",
      "8. **테스트·CI**  \n",
      "   - `unittest`, `pytest`  \n",
      "   - GitHub Actions, GitLab CI  \n",
      "\n",
      "9. **배포·운영**  \n",
      "   - Docker, Kubernetes, 서버리스(AWS Lambda)  \n",
      "   - `pyinstaller`(실행 파일 생성)  \n",
      "\n",
      "---\n",
      "\n",
      "## 7. 파이썬 커뮤니티와 자료\n",
      "\n",
      "| 종류 | URL | 특징 |\n",
      "|------|-----|------|\n",
      "| **공식 문서** | <https://docs.python.org/3/> | 최신 스펙·예제 |\n",
      "| **패키지 인덱스** | <https://pypi.org/> | 300k+ 서드파티 패키지 |\n",
      "| **튜토리얼** | <https://realpython.com/> | 실무 중심 가이드 |\n",
      "| **Q&A** | <https://stackoverflow.com/questions/tagged/python> | 문제 해결에 최적 |\n",
      "| **커뮤니티** | Reddit r/Python, Discord, Slack | 토론·정보 공유 |\n",
      "| **학습 플랫폼** | Coursera, edX, Udemy, Fast.ai | 단계별 강의 |\n",
      "\n",
      "---\n",
      "\n",
      "## 8. 결론\n",
      "\n",
      "- **파이썬은 “읽기 쉬운 코드 + 풍부한 라이브러리”** 라는 조합 덕분에 **시작이 쉽고** **실제 프로젝트에 바로 적용** 할 수 있는 언어입니다.\n",
      "- **데이터 과학·AI** 분야에서는 사실상 표준이 되었으며, **웹·자동화·시스템 관리** 등에서도 강력한 입지를 가지고 있습니다.\n",
      "- **성능**이 중요한 경우 C 확장, PyPy, 멀티프로세싱 등을 적절히 활용하면 충분히 보완할 수 있습니다.\n",
      "- 활발한 **오픈소스 커뮤니티**와 **광범위한 생태계** 덕분에 새로운 기술을 배우거나 문제를 해결할 때 언제든지 도움을 받을 수 있습니다.\n",
      "\n",
      "> **한 줄 요약**: 파이썬은 **읽기 쉬운 문법**과 **다양한 라이브러리**를 갖춘 **범용 프로그래밍 언어**이며, 초보자부터 전문가까지 폭넓게 활용할 수 있는 강력한 도구입니다. \n",
      "\n",
      "궁금한 점이 더 있으면 언제든 질문해주세요! 🚀\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(type(response))\n",
    "    print(\"응답:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001E1163E98B0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001E1163EA300>, root_client=<openai.OpenAI object at 0x000001E1163E99A0>, root_async_client=<openai.AsyncOpenAI object at 0x000001E1163E9CA0>, model_name='openai/gpt-oss-120b', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"input\":\"LangChain은 무엇인가요\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "## LangChain이란?\n",
      "\n",
      "**LangChain**은 **대규모 언어 모델(LLM)**을 **애플리케이션 수준**으로 활용할 수 있게 도와주는 **오픈소스 프레임워크**입니다.  \n",
      "LLM을 단순히 “프롬프트 → 답변” 형태로 사용하는 것이 아니라, **데이터베이스, 검색 엔진, 툴, 사용자 인터페이스** 등 다양한 외부 시스템과 **연결하고** **복합적인 워크플로우**를 구성하도록 설계되었습니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 핵심 목표\n",
      "\n",
      "| 목표 | 설명 |\n",
      "|------|------|\n",
      "| **모듈화** | LLM, 프롬프트, 메모리, 체인, 에이전트 등을 독립적인 컴포넌트로 제공 → 필요에 따라 조합·교체 가능 |\n",
      "| **확장성** | 여러 LLM(OpenAI, Anthropic, Cohere, Llama, Azure 등)과 백엔드(벡터 DB, 검색 API, 도구)와 쉽게 연결 |\n",
      "| **생산성** | 복잡한 프롬프트 엔지니어링·체인 설계 작업을 추상화해, 최소 코드로 고급 기능 구현 |\n",
      "| **표준화** | 다양한 LLM 기반 애플리케이션(챗봇, RAG, 자동화 에이전트 등)에서 공통으로 사용할 수 있는 인터페이스 제공 |\n",
      "\n",
      "---\n",
      "\n",
      "## 주요 구성 요소\n",
      "\n",
      "| 구성 요소 | 역할 | 주요 클래스/함수 |\n",
      "|-----------|------|-----------------|\n",
      "| **LLM 래퍼** | OpenAI, Anthropic, Llama 등 실제 모델 호출을 추상화 | `OpenAI`, `ChatOpenAI`, `Anthropic`, `Cohere`, `LlamaCPP` |\n",
      "| **프롬프트 템플릿** | 변수 삽입, 체인 연결 시 재사용 가능한 프롬프트 정의 | `PromptTemplate`, `ChatPromptTemplate` |\n",
      "| **체인(Chain)** | 여러 LLM 호출·프롬프트·툴을 순차·조건부로 연결 | `LLMChain`, `SequentialChain`, `SimpleSequentialChain` |\n",
      "| **에이전트(Agent)** | “도구를 사용해 목표 달성”을 자동으로 계획·실행 (예: 웹 검색, 코드 실행) | `AgentExecutor`, `Tool`, `ZeroShotAgent`, `ConversationalAgent` |\n",
      "| **메모리(Memory)** | 대화 이력·컨텍스트를 유지해 상태ful 대화 구현 | `ConversationBufferMemory`, `ConversationSummaryMemory` |\n",
      "| **벡터 스토어 & 검색** | 문서 임베딩 → 유사도 검색 → RAG (Retrieval‑Augmented Generation) | `FAISS`, `Pinecone`, `Weaviate`, `Chroma`, `Milvus` |\n",
      "| **툴(Tool)** | LLM이 호출할 수 있는 외부 기능 (검색, 계산, API 호출 등) | `SerpAPIWrapper`, `RequestsGetTool`, `PythonREPLTool` |\n",
      "| **콜백·로깅** | 실행 흐름, 토큰 사용량, 에러 등을 실시간 감시 | `CallbackManager`, `StdOutCallbackHandler` |\n",
      "\n",
      "---\n",
      "\n",
      "## 대표적인 사용 시나리오\n",
      "\n",
      "| 시나리오 | 구현 흐름 (예시) |\n",
      "|----------|-------------------|\n",
      "| **Q&A 챗봇** | `ChatOpenAI` + `ConversationBufferMemory` → 사용자의 질문을 기억하고 자연스럽게 이어지는 대화 |\n",
      "| **RAG (Retrieval‑Augmented Generation)** | 문서 → `Embedding` → `FAISS` 벡터 스토어 → 질의 → 가장 유사한 문서 3개 추출 → `LLMChain`에 프롬프트로 전달 → 답변 생성 |\n",
      "| **자동화 에이전트** | 목표(예: “날씨와 주식 정보를 알려줘”) → `ZeroShotAgent`가 `SerpAPI`와 `AlphaVantage` 같은 툴을 순차적으로 호출 → 결과 종합 후 사용자에게 전달 |\n",
      "| **코드 생성·실행** | `ChatOpenAI` → `PythonREPLTool` (코드 실행) → 실행 결과를 프롬프트에 반영 → 반복적인 디버깅/개선 |\n",
      "| **멀티모달 파이프라인** | 이미지 → `CLIP` 임베딩 → 텍스트와 결합 → `LLMChain`에 전달 → 이미지 설명·질문 답변 |\n",
      "\n",
      "---\n",
      "\n",
      "## 간단한 코드 예시 (Python)\n",
      "\n",
      "아래는 **FAISS 기반 RAG** 파이프라인을 30줄 내외로 구현한 예시입니다.\n",
      "\n",
      "```python\n",
      "from langchain.embeddings import OpenAIEmbeddings\n",
      "from langchain.vectorstores import FAISS\n",
      "from langchain.llms import OpenAI\n",
      "from langchain.chains import RetrievalQA\n",
      "from langchain.prompts import PromptTemplate\n",
      "\n",
      "# 1️⃣ 문서 로드 & 임베딩\n",
      "docs = [\"LangChain은 LLM을 애플리케이션 수준으로 연결하는 프레임워크입니다.\",\n",
      "        \"벡터 DB와 연동해 RAG를 손쉽게 구현할 수 있습니다.\"]\n",
      "embeddings = OpenAIEmbeddings()\n",
      "vectorstore = FAISS.from_texts(docs, embeddings)\n",
      "\n",
      "# 2️⃣ Retrieval QA 체인 정의\n",
      "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
      "prompt = PromptTemplate(\n",
      "    input_variables=[\"context\", \"question\"],\n",
      "    template=\"다음 문서를 참고해 질문에 답하세요.\\n문서: {context}\\n질문: {question}\"\n",
      ")\n",
      "qa_chain = RetrievalQA.from_chain_type(\n",
      "    llm=OpenAI(),\n",
      "    retriever=retriever,\n",
      "    chain_type=\"stuff\",\n",
      "    return_source_documents=True,\n",
      "    prompt=prompt,\n",
      ")\n",
      "\n",
      "# 3️⃣ 질문 실행\n",
      "query = \"LangChain을 사용하면 어떤 장점이 있나요?\"\n",
      "result = qa_chain({\"query\": query})\n",
      "\n",
      "print(\"답변:\", result[\"result\"])\n",
      "print(\"\\n참조 문서:\", [doc.page_content for doc in result[\"source_documents\"]])\n",
      "```\n",
      "\n",
      "**핵심 포인트**\n",
      "\n",
      "1. `OpenAIEmbeddings` → 텍스트를 벡터화  \n",
      "2. `FAISS` → 로컬 메모리 벡터 DB (다른 DB로 교체 가능)  \n",
      "3. `RetrievalQA` → 검색‑응답 체인, `prompt` 로 답변 형식 지정  \n",
      "4. `return_source_documents=True` 로 근거 문서도 함께 반환\n",
      "\n",
      "---\n",
      "\n",
      "## 왜 LangChain을 선택해야 할까?\n",
      "\n",
      "| 장점 | 상세 설명 |\n",
      "|------|-----------|\n",
      "| **다양한 LLM 지원** | OpenAI, Anthropic, Cohere, Llama 등 최신 모델을 손쉽게 교체 |\n",
      "| **플러그인·툴 생태계** | 검색, 데이터베이스, 코드 실행, 파일 시스템 등 수백 개 툴이 미리 구현돼 있음 |\n",
      "| **유연한 파이프라인** | 단순 체인부터 복잡한 에이전트까지 단계별로 확장 가능 |\n",
      "| **커뮤니티·생태계** | GitHub ★ 30k+, 활발한 포럼·Discord, 공식 문서·템플릿 풍부 |\n",
      "| **언어·프레임워크 독립** | Python이 기본이지만, JavaScript/TS, Java, Go 등 다른 언어용 래퍼도 점차 확대 중 |\n",
      "\n",
      "---\n",
      "\n",
      "## 시작하기\n",
      "\n",
      "1. **설치**  \n",
      "   ```bash\n",
      "   pip install langchain openai   # 기본 패키지\n",
      "   # 필요에 따라 FAISS, pinecone, chromadb 등 추가 설치\n",
      "   ```\n",
      "\n",
      "2. **API 키 설정** (OpenAI 예시)  \n",
      "   ```bash\n",
      "   export OPENAI_API_KEY=\"sk-...\"\n",
      "   ```\n",
      "\n",
      "3. **첫 번째 체인 실행** (위 예시와 같이 간단히 구현)\n",
      "\n",
      "4. **공식 문서** → <https://python.langchain.com/>  \n",
      "   **GitHub** → <https://github.com/langchain-ai/langchain>\n",
      "\n",
      "---\n",
      "\n",
      "## 마무리\n",
      "\n",
      "- **LangChain**은 “LLM + 외부 시스템 = 실제 서비스” 라는 목표를 실현하기 위한 **모듈형 툴킷**입니다.  \n",
      "- 프롬프트 엔지니어링에 머무르지 않고 **검색, 메모리, 툴, 에이전트** 등을 결합해 **복합적인 AI 애플리케이션**을 빠르게 프로토타이핑·배포할 수 있습니다.  \n",
      "- Python 기반이 가장 성숙하지만, 다른 언어에서도 점차 지원이 확대되고 있어 **멀티플랫폼** AI 개발에 유용합니다.\n",
      "\n",
      "궁금한 점이나 구체적인 구현 사례가 필요하면 언제든 질문해주세요! 🚀\n"
     ]
    }
   ],
   "source": [
    "print(type(response))\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
