{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplate \n",
    "* [PromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html#langchain_core.prompts.prompt.PromptTemplate)\n",
    "* [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html#langchain_core.prompts.chat.ChatPromptTemplate)\n",
    "* [ChatMessagePromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatMessagePromptTemplate.html#langchain_core.prompts.chat.ChatMessagePromptTemplate)\n",
    "* [FewShotPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotPromptTemplate.html#langchain_core.prompts.few_shot.FewShotPromptTemplate)\n",
    "* PartialPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_w\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) PromptTemplate 의 from_template() 함수 사용\n",
    "* 주로 LLM(텍스트 완성형 모델, ex. Ollama, GPT-3.5)과 함께 사용\n",
    "* 하나의 문자열 프롬프트를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ChatGPT는 대규모 텍스트 데이터를 이용해 다음에 올 단어를 예측하도록 훈련된 트랜스포머 기반 언어 모델입니다. 이 과정에서 모델은 '\n",
      " '문맥을 이해하고 의미를 파악하기 위해 수백억 개의 파라미터를 조정하며, 손실 함수(예: 교차 엔트로피)를 최소화하도록 최적화됩니다. '\n",
      " '최종적으로, 학습된 파라미터를 바탕으로 사용자의 입력에 대해 가장 가능성이 높은 답변을 생성합니다.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from pprint import pprint\n",
    "\n",
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3})\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) PromptTemplate 결합하기\n",
    "* 동일한 Prompt 패턴을 사용하지만 여러 개의 질문을 작성해서 LLM을 실행할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['count', 'language', 'model_name'] input_types={} partial_variables={} template='{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.'\n",
      "('**ChatGPT 모델의 학습 원리 (3문장)**  \\n'\n",
      " '1. 방대한 텍스트 데이터를 토큰 단위로 분할해, 앞뒤 문맥을 예측하는 ‘자기 지도 학습(unsupervised '\n",
      " 'pre‑training)’을 수행합니다.  \\n'\n",
      " '2. 학습 과정에서는 트랜스포머 아키텍처의 다중‑헤드 어텐션을 이용해 단어 간 장기 의존성을 효율적으로 파악합니다.  \\n'\n",
      " '3. 사전 학습된 가중치를 기반으로 특정 작업(예: 질문‑응답, 번역)용 데이터셋으로 ‘지도 학습(fine‑tuning)’하거나, '\n",
      " '프롬프트와 샘플링 기법으로 즉시 활용합니다.  \\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### ChatGPT 모델의 장점 요약  \\n'\n",
      " '\\n'\n",
      " '| 장점 | 설명 |\\n'\n",
      " '|------|------|\\n'\n",
      " '| **범용성** | 다양한 언어와 주제에 대해 자연스러운 대화를 생성할 수 있어, 챗봇·문서 요약·코드 작성 등 여러 분야에 적용 가능 '\n",
      " '|\\n'\n",
      " '| **문맥 이해** | 긴 텍스트에서도 앞뒤 관계를 파악해 일관된 답변을 제공, 복잡한 질문에도 논리적인 흐름 유지 |\\n'\n",
      " '| **지속적 개선** | 대규모 데이터와 최신 아키텍처를 활용해 지속적으로 성능이 향상되며, 사용자 피드백을 반영한 업데이트가 가능 '\n",
      " '|\\n'\n",
      " '| **다양한 출력 제어** | 온도·탑‑P·프롬프트 엔지니어링 등 파라미터 조절을 통해 창의성·정확성·길이 등을 자유롭게 조정 가능 '\n",
      " '|\\n'\n",
      " '| **확장성** | 클라우드·온‑프레미스 모두에서 배포가 가능하고, API 형태로 손쉽게 다른 시스템에 통합할 수 있음 |\\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### ChatGPT와 비슷한 AI 모델 (한국어 모델명)\\n'\n",
      " '\\n'\n",
      " '| 모델명 (한국어) | 원본 영문명 | 주요 특징 |\\n'\n",
      " '|----------------|------------|-----------|\\n'\n",
      " '| **GPT‑3** | GPT‑3 | 175\\u202fB 파라미터, 다양한 자연어 처리 작업에 활용 |\\n'\n",
      " '| **GPT‑4** | GPT‑4 | 멀티모달(텍스트·이미지) 지원, 향상된 추론 능력 |\\n'\n",
      " '| **라마(LLaMA)** | LLaMA | 메타에서 개발, 효율적인 파라미터 대비 성능 |\\n'\n",
      " '| **클로드(Claude)** | Claude | Anthropic이 만든 안전성·윤리성 강화 모델 |\\n'\n",
      " '| **파람(PaLM)** | PaLM | 구글의 대규모 언어 모델, 540\\u202fB 파라미터 |\\n'\n",
      " '| **제미니(Gemini)** | Gemini | 구글 딥마인드의 최신 멀티모달 모델 |\\n'\n",
      " '| **코GPT(KoGPT)** | KoGPT | 한국어 데이터에 특화된 사전 학습 모델 |\\n'\n",
      " '| **코알파카(KoAlpaca)** | KoAlpaca | 한국어 지시‑응답 데이터로 파인튜닝된 경량 모델 |\\n'\n",
      " '| **한글‑BERT(HanBERT)** | Korean‑BERT | 한국어 이해에 최적화된 BERT 기반 모델 |\\n'\n",
      " '| **스마트AI(SMART‑AI)** | SMART‑AI | 국내 기업이 개발한 대화형 한국어 AI 플랫폼 |\\n'\n",
      " '\\n'\n",
      " '이 모델들은 모두 트랜스포머 기반이며, 사전 학습 후 특정 작업에 맞게 파인튜닝하거나 프롬프트 엔지니어링을 통해 활용됩니다. 필요에 따라 '\n",
      " '오픈소스·상용·클라우드 형태로 선택해 사용할 수 있습니다.')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# 템플릿에 값을 채워서 프롬프트를 완성\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# 문자열 템플릿 결합 (PromptTemplate + PromptTemplate + 문자열)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\")\n",
    "              + \"\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.\"\n",
    ")\n",
    "#combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"한국어\")\n",
    "print(combined_prompt)\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"한국어\"})\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PromptTemplate 의 파라미터를 배열 형태로 하여 여러개 사용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.', 'Gemini 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.', 'claude 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.']\n",
      "<class 'str'> GPT-4 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.\n",
      "('GPT-4는 대규모 텍스트 데이터를 이용해 자기 지도 학습(self‑supervised learning) 방식으로 사전 '\n",
      " '학습(pre‑training)됩니다. 이 과정에서 모델은 입력 토큰 시퀀스를 보고 다음에 올 토큰을 예측하도록 최적화되며, 이를 통해 '\n",
      " '언어 구조와 의미를 내부적으로 파악하게 됩니다. 이후 특정 작업에 맞추어 작은 규모의 라벨 데이터로 미세 '\n",
      " '조정(fine‑tuning)하거나 인간 피드백을 활용한 강화 학습(RLHF)을 적용해 실제 사용 환경에 맞는 성능을 향상시킵니다.')\n",
      "<class 'str'> Gemini 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.\n",
      "('Gemini 모델은 방대한 텍스트와 이미지·음성 등 멀티모달 데이터를 이용해 Transformer 기반의 대규모 '\n",
      " '사전학습(pre‑training)을 진행합니다.  \\n'\n",
      " '사전학습 단계에서는 다음 토큰을 예측하거나 마스크된 부분을 복원하는 자기지도(self‑supervised) 목표를 통해 언어와 시각 '\n",
      " '정보를 동시에 학습합니다.  \\n'\n",
      " '그 후, 인간이 만든 지시문과 대화 데이터를 활용한 지도학습(fine‑tuning)으로 다양한 작업에 대한 응답 능력을 '\n",
      " '향상시킵니다.  \\n'\n",
      " '마지막으로, 인간 피드백을 기반으로 한 강화학습(RLHF)을 적용해 실제 사용 환경에서 더 안전하고 유용한 행동을 하도록 최적화합니다.')\n",
      "<class 'str'> claude 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.\n",
      "('Claude 모델은 대규모 텍스트 데이터를 기반으로 **자기지도학습**(self‑supervised learning) 방식을 '\n",
      " '사용합니다.  \\n'\n",
      " '먼저, 텍스트를 무작위로 마스킹하거나 다음 문장을 예측하도록 하여 **언어 모델링** 과제를 수행하고, 이를 통해 문맥을 이해하는 능력을 '\n",
      " '습득합니다.  \\n'\n",
      " '그 후, 인간 피드백을 활용한 **RLHF**(Reinforcement Learning from Human Feedback) 단계에서, '\n",
      " '모델이 생성한 답변을 사람 평가자가 순위 매기고, 이를 보상 모델로 학습시켜 원하는 방향으로 행동을 조정합니다.  \\n'\n",
      " '이러한 두 단계(사전 학습 + 인간 피드백 기반 미세조정)를 거쳐 Claude는 자연스러운 대화와 복잡한 추론을 수행할 수 있게 됩니다.')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 3},\n",
    "    {\"model_name\": \"Gemini\", \"count\": 4},\n",
    "    {\"model_name\": \"claude\", \"count\": 4},\n",
    "]\n",
    "\n",
    "# 여러 개의 프롬프트를 미리 생성\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions]\n",
    "print(formatted_prompts)  # 미리 생성된 질문 목록 확인\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "for prompt in formatted_prompts:\n",
    "    print(type(prompt), prompt)\n",
    "    response = llm.invoke(prompt)\n",
    "    pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) ChatPromptTemplate\n",
    "* Tuple 형태의 system, user, assistant 메시지 지원\n",
    "* 여러 개의 메시지를 조합하여 LLM에게 전달 가능\n",
    "* 간결성과 가독성이 높고 단순한 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='This system is an expert in answering questions about AI. Please provide clear and detailed explanations.', additional_kwargs={}, response_metadata={}), HumanMessage(content='ChatGPT 모델의 학습 원리를 설명해 주세요.', additional_kwargs={}, response_metadata={})]\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "## ChatGPT 모델이 어떻게 학습되는지 (한국어 상세 설명)\n",
      "\n",
      "아래에서는 **ChatGPT**(또는 일반적인 GPT‑계열 대형 언어 모델)의 학습 과정을 크게 **세 단계**로 나누어 설명합니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣ 사전 학습 (Pre‑training) – “거대한 텍스트를 읽는 단계”\n",
      "\n",
      "| 단계 | 핵심 내용 | 왜 필요한가? |\n",
      "|------|-----------|--------------|\n",
      "| **데이터 수집** | 웹 페이지, 책, 논문, 뉴스, 위키피디아 등 수백 억 토큰 규모의 텍스트를 크롤링·정제 | 모델이 다양한 언어·도메인 지식을 습득하도록 함 |\n",
      "| **토크나이징** | 텍스트 → **토큰**(보통 BPE/Byte‑Pair Encoding) <br>예: “ChatGPT는” → `[Chat][##GPT][##는]` | 어휘 크기를 수천~수만 개 수준으로 제한하면서도 희귀어·신조어를 처리 가능 |\n",
      "| **Transformer 아키텍처** | - **입력 임베딩** + **포지션 임베딩** <br>- **다중 헤드 셀프‑어텐션** (Self‑Attention) <br>- **피드‑포워드 레이어** (FFN) <br>- **잔차 연결 + 레이어 정규화** | 셀프‑어텐션은 문맥 전체를 한 번에 바라볼 수 있어, 긴 문장·문서에서도 장기 의존성을 학습 |\n",
      "| **학습 목표** (언어 모델링) | **다음 토큰 예측**:  \\(\\displaystyle \\max_{\\theta}\\sum_{t} \\log P_{\\theta}(x_t \\mid x_{<t})\\) <br>손실 함수: **교차 엔트로피** | 모델이 “다음에 올 단어”를 가장 확률 높게 맞추도록 훈련 |\n",
      "| **최적화** | - **AdamW** 옵티마이저 (β₁≈0.9, β₂≈0.999) <br>- **학습률 스케줄링**: Warm‑up → cosine decay <br>- **배치 크기**: 수천~수만 시퀀스 (GPU/TPU 클러스터) | 대규모 파라미터(수십억~수천억)와 방대한 데이터에 안정적으로 수렴시키기 위함 |\n",
      "| **분산 학습** | **데이터 병렬** + **모델 병렬** (Tensor Parallel, Pipeline Parallel) <br>예: 1조 파라미터 모델은 수백 개 GPU에 나눠서 학습 | 메모리·연산 한계를 넘어서는 모델을 학습할 수 있게 함 |\n",
      "\n",
      "> **핵심 포인트**: 사전 학습 단계에서는 “**언어 자체**”를 이해하도록 하는 것이 목표이며, 특정 작업에 대한 라벨(정답)은 사용되지 않는다. 모델은 “문맥 → 다음 토큰”이라는 일반적인 규칙을 스스로 발견한다.\n",
      "\n",
      "---\n",
      "\n",
      "## 2️⃣ 지도 학습 (Supervised Fine‑tuning) – “특정 작업에 맞추는 단계”\n",
      "\n",
      "| 내용 | 설명 |\n",
      "|------|------|\n",
      "| **데이터** | 인간이 만든 질문‑답변, 대화 로그, 요약문, 코드 등 **태스크‑특화**된 데이터셋 |\n",
      "| **목표** | 입력(프롬프트) → 원하는 출력(답변) 형태를 **직접** 학습<br>손실: 여전히 교차 엔트로피, 하지만 정답이 명확히 주어짐 |\n",
      "| **방법** | 사전 학습된 가중치를 **초기값**으로 사용하고, 비교적 작은 학습률(예: 1e‑5)로 몇 epoch만 추가 학습 |\n",
      "| **왜 하는가?** | - 사전 학습만으로는 “**정확히** 원하는 형식·톤·안전성”을 보장하기 어려움 <br>- 특정 도메인(법률, 의료 등)에서 정확도를 높이기 위해 필요 |\n",
      "\n",
      "---\n",
      "\n",
      "## 3️⃣ 강화 학습을 통한 인간 피드백 (RLHF) – “인간 선호를 반영하는 단계”\n",
      "\n",
      "1. **Human‑written demonstrations**  \n",
      "   - 전문가가 만든 **프롬프트‑답변 쌍**을 모델에 제공해, **초기 정책**(즉, 초벌 답변)을 학습한다.\n",
      "\n",
      "2. **Reward Model (RM) 구축**  \n",
      "   - 여러 모델 출력(답변)들을 인간 평가자(라벨러)가 **선호도**(예: “가장 좋은 답변”, “그냥 답변”)로 순위 매긴다.  \n",
      "   - 이 순위를 **쌍wise loss** 혹은 **교차 엔트로피** 형태로 학습해 **보상 함수** \\(R_{\\phi}(output)\\) 를 만든다.\n",
      "\n",
      "3. **Proximal Policy Optimization (PPO)** 등 강화학습 알고리즘 적용  \n",
      "   - 현재 정책(언어 모델) \\(\\pi_{\\theta}\\) 로부터 답변을 생성하고, 보상 모델이 산출한 보상 \\(R_{\\phi}\\) 를 이용해 **정책을 업데이트**한다.  \n",
      "   - PPO는 **KL‑제약**을 두어 정책이 급격히 변하지 않게 하면서도 보상을 최대화하도록 한다.\n",
      "\n",
      "4. **반복**  \n",
      "   - 새로운 답변을 수집 → 인간이 다시 평가 → 보상 모델 재학습 → 정책 재학습 …을 **여러 라운드** 진행한다.\n",
      "\n",
      "### RLHF의 효과\n",
      "- **안전성**: 유해·편향된 내용이 낮아짐.  \n",
      "- **유용성**: 인간이 실제로 선호하는 “명확하고 구체적인” 답변을 더 많이 생성.  \n",
      "- **일관성**: 같은 프롬프트에 대해 일관된 스타일·톤을 유지.\n",
      "\n",
      "---\n",
      "\n",
      "## 📚 전체 흐름 요약 (시각화)\n",
      "\n",
      "```\n",
      "[대규모 텍스트] → 토크나이징 → Transformer (사전 학습) → [일반 언어 이해]\n",
      "        |\n",
      "        |  (지도 학습)\n",
      "        v\n",
      "[작업‑특화 데이터] → Fine‑tuning → [특정 태스크에 맞는 모델]\n",
      "        |\n",
      "        |  (RLHF)\n",
      "        v\n",
      "[인간 피드백] → Reward Model → PPO → [안전·유용·일관성 강화]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## 🛠️ 주요 기술·용어 정리\n",
      "\n",
      "| 용어 | 설명 |\n",
      "|------|------|\n",
      "| **Transformer** | 셀프‑어텐션 기반 신경망. 입력 시퀀스 전체를 동시에 처리해 병렬화가 뛰어남. |\n",
      "| **Self‑Attention** | 각 토큰이 다른 모든 토큰과의 관계를 가중합으로 학습, “누가 누구에게 중요한가”를 스스로 판단. |\n",
      "| **BPE (Byte‑Pair Encoding)** | 가장 자주 등장하는 문자·문자쌍을 점차 병합해 어휘를 구성하는 토크나이징 방법. |\n",
      "| **Cross‑Entropy Loss** | 실제 토큰과 모델이 예측한 확률 분포 사이의 차이를 측정. |\n",
      "| **AdamW** | 가중치 감쇠(L2 정규화)를 포함한 Adam 옵티마이저. |\n",
      "| **PPO (Proximal Policy Optimization)** | 정책 업데이트 시 KL‑다이버전스 제한을 두어 안정성을 높이는 강화학습 알고리즘. |\n",
      "| **Reward Model** | 인간 피드백을 기반으로 만든 “답변이 얼마나 좋은가”를 점수화하는 모델. |\n",
      "| **Few‑Shot / Zero‑Shot** | 사전 학습만으로도 (few‑shot) 혹은 전혀 (zero‑shot) 새로운 태스크를 수행할 수 있는 능력. |\n",
      "\n",
      "---\n",
      "\n",
      "## 📌 핵심 포인트 다시 정리\n",
      "\n",
      "1. **대규모 텍스트**를 **다음 토큰 예측**이라는 단순 목표로 학습 → 언어 구조와 세계 지식 습득.  \n",
      "2. **지도 학습**으로 특정 형식·도메인에 맞는 **출력**을 학습.  \n",
      "3. **인간 피드백**을 보상으로 활용한 **RLHF** 단계에서 안전성·유용성을 크게 향상.  \n",
      "4. 전체 과정은 **분산 GPU/TPU 클러스터**와 **고효율 옵티마이저·스케줄링**을 사용해 수주~수개월에 걸쳐 진행된다.\n",
      "\n",
      "---\n",
      "\n",
      "### 참고 자료 (심화 학습용)\n",
      "\n",
      "| 논문·블로그 | 주요 내용 |\n",
      "|------------|-----------|\n",
      "| **“Attention Is All You Need” (Vaswani et al., 2017)** | Transformer 기본 구조 |\n",
      "| **“Improving Language Understanding by Generative Pre‑Training” (GPT‑1, 2018)** | 사전 학습 개념 도입 |\n",
      "| **“Language Models are Few‑Shot Learners” (GPT‑3, 2020)** | 대규모 사전 학습 + few‑shot |\n",
      "| **“Fine‑Tuning Language Models from Human Preferences” (Ziegler et al., 2019)** | RLHF 초기 연구 |\n",
      "| **OpenAI blog – “ChatGPT and the Reinforcement Learning from Human Feedback (RLHF) pipeline”** | 최신 RLHF 파이프라인 설명 |\n",
      "\n",
      "---\n",
      "\n",
      "**요약**: ChatGPT는 방대한 텍스트를 통해 일반 언어 능력을 습득하고, 지도 학습·RLHF를 통해 인간이 원하는 형태와 안전성을 갖춘 대화형 AI로 진화합니다. 이 과정은 **Transformer** 기반 모델, **대규모 분산 학습**, **인간 피드백을 보상으로 활용한 강화학습**이라는 세 가지 핵심 기술이 결합된 결과입니다.\n"
     ]
    }
   ],
   "source": [
    "# 2-튜플 형태의 메시지 목록으로 프롬프트 생성 (type, content)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    # role, message\n",
    "    (\"system\", \"This system is an expert in answering questions about {topic}. Please provide clear and detailed explanations.\"),\n",
    "    (\"human\", \"{model_name} 모델의 학습 원리를 설명해 주세요.\"),\n",
    "])\n",
    "\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", model_name=\"ChatGPT\")\n",
    "print(messages)\n",
    "\n",
    "# 생성한 메시지를 바로 주입하여 호출하기\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(type(response))\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "## ChatGPT 모델이 학습되는 원리  \n",
      "\n",
      "아래에서는 ChatGPT(또는 일반적인 대형 언어 모델)가 어떻게 학습되는지를 **전처리 → 사전학습 → 파인튜닝 → 강화학습**의 흐름으로 나누어 단계별로 설명합니다.  \n",
      "\n",
      "---\n",
      "\n",
      "### 1️⃣ 데이터 전처리 (Pre‑processing)\n",
      "\n",
      "| 단계 | 내용 | 왜 필요한가? |\n",
      "|------|------|--------------|\n",
      "| **텍스트 수집** | 웹 페이지, 책, 논문, 대화 로그 등 다양한 출처에서 수십억 단어를 모음 | 모델이 **다양한 언어·도메인**을 이해하도록 하기 위함 |\n",
      "| **정제(Cleaning)** | HTML 태그 제거, 중복 문장 삭제, 비속어·민감 정보 필터링 등 | 학습 효율을 높이고, 불필요하거나 위험한 데이터가 모델에 들어가지 않게 함 |\n",
      "| **문장 토큰화** | 텍스트를 **토큰**(보통 서브워드 단위, 예: BPE, WordPiece)으로 변환 | 모델이 고정된 어휘 집합(보통 30k~50k 토큰)으로 모든 문자열을 표현할 수 있게 함 |\n",
      "| **시퀀스 길이 맞추기** | 일정 길이(예: 2048 토큰)로 패딩하거나 잘라서 배치에 맞춤 | GPU/TPU 메모리 효율을 최적화하고, 배치 연산을 가능하게 함 |\n",
      "\n",
      "---\n",
      "\n",
      "### 2️⃣ 사전학습 (Pre‑training) – **자기지도 학습 (Self‑Supervised Learning)**  \n",
      "\n",
      "#### 2.1 모델 구조: 트랜스포머(Transformer)  \n",
      "- **Encoder‑Decoder** 구조 중 **Decoder‑only** (GPT 시리즈) 사용  \n",
      "- 기본 블록: **멀티‑헤드 셀프‑어텐션** + **피드‑포워드 네트워크**  \n",
      "- **잔차 연결 (Residual)** + **Layer Normalization** 으로 안정적인 학습  \n",
      "\n",
      "#### 2.2 학습 목표  \n",
      "- **다음 토큰 예측 (Next‑Token Prediction)**:  \n",
      "  \\[\n",
      "  \\max_{\\theta}\\ \\sum_{t=1}^{T}\\log P_{\\theta}(x_t \\mid x_{<t})\n",
      "  \\]\n",
      "  여기서 \\(x_t\\)는 시퀀스의 t번째 토큰, \\(\\theta\\)는 모델 파라미터.  \n",
      "- **Cross‑Entropy 손실**을 사용해 실제 토큰과 예측 확률 분포 사이의 차이를 최소화.\n",
      "\n",
      "#### 2.3 학습 과정  \n",
      "1. **배치 구성**: 동일한 길이의 토큰 시퀀스를 여러 개 모아 하나의 배치를 만든다.  \n",
      "2. **포워드 패스**: 각 토큰을 입력으로 하여 Transformer가 다음 토큰에 대한 확률 분포를 출력한다.  \n",
      "3. **손실 계산**: 정답 토큰과 모델이 예측한 확률 분포 사이의 교차 엔트로피 손실을 구한다.  \n",
      "4. **백워드 패스**: 손실에 대한 그래디언트를 계산하고, **AdamW** 같은 옵티마이저로 파라미터를 업데이트한다.  \n",
      "5. **스케줄링**: 학습률을 **Warm‑up → Linear Decay** 등으로 조절해 안정적인 수렴을 돕는다.  \n",
      "\n",
      "#### 2.4 스케일링 팁  \n",
      "- **모델 규모**: 파라미터 수(수억~수천억)와 레이어 수, 헤드 수를 늘릴수록 표현력이 증가하지만 계산 비용도 크게 늘어남.  \n",
      "- **데이터 규모**: 토큰 수가 많을수록(수조 토큰) 일반화 능력이 향상된다.  \n",
      "- **컴퓨팅**: 수천 개의 GPU/TPU를 사용해 **데이터 병렬**·**모델 병렬**·**파이프라인 병렬**을 결합한 방식으로 학습한다.\n",
      "\n",
      "---\n",
      "\n",
      "### 3️⃣ 파인튜닝 (Fine‑tuning) – **지도학습 기반 특화**  \n",
      "\n",
      "사전학습만으로는 **특정 작업**(예: 질문‑답변, 번역, 코딩)에서 최적의 성능을 보장하기 어렵다.  \n",
      "1. **작업‑특정 데이터**를 준비한다. (예: QA 쌍, 대화 로그, 코드 스니펫 등)  \n",
      "2. **시퀀스‑투‑시퀀스** 형태로 입력‑출력 페어를 만든 뒤, 동일한 **다음 토큰 예측** 손실을 사용해 모델을 추가 학습한다.  \n",
      "3. 필요에 따라 **학습률**을 사전학습보다 낮게 설정해 **과적합**을 방지한다.\n",
      "\n",
      "---\n",
      "\n",
      "### 4️⃣ 강화학습을 통한 정교화 (RLHF: Reinforcement Learning from Human Feedback)\n",
      "\n",
      "ChatGPT와 같이 **대화형** 모델은 단순히 다음 토큰을 맞추는 것보다 **사용자 의도**와 **안전성**을 고려해야 한다. 이를 위해 다음 과정을 거친다.\n",
      "\n",
      "| 단계 | 설명 |\n",
      "|------|------|\n",
      "| **1️⃣ 인간 라벨링** | 인간 평가자가 여러 모델 응답을 비교·순위 매김 (예: “가장 유용함”, “가장 안전함”) |\n",
      "| **2️⃣ 보상 모델 (Reward Model) 학습** | 라벨링 데이터를 사용해 **보상 함수** \\(R(y)\\)를 학습한다. 보상 모델은 특정 응답이 얼마나 좋은지를 점수화한다. |\n",
      "| **3️⃣ 정책 최적화** | 현재 언어 모델을 **정책** \\(\\pi_{\\theta}\\)라 보고, **Proximal Policy Optimization (PPO)** 같은 RL 알고리즘을 적용한다. 목표는 기대 보상 \\(\\mathbb{E}_{y\\sim \\pi_{\\theta}}[R(y)]\\)을 최대화하는 것이다. |\n",
      "| **4️⃣ 안전성 필터링** | RL 단계 후에도 위험하거나 부적절한 출력을 억제하기 위해 **규칙 기반 필터**·**후처리**를 추가한다. |\n",
      "\n",
      "#### RLHF 흐름 예시\n",
      "1. **샘플링**: 현재 모델이 여러 후보 답변을 생성한다.  \n",
      "2. **보상 평가**: 보상 모델이 각 후보에 점수를 부여한다.  \n",
      "3. **PPO 업데이트**: 점수가 높은 답변을 더 많이 생성하도록 정책을 조정한다.  \n",
      "4. **반복**: 위 과정을 수십만~수백만 번 반복해 점진적으로 품질을 향상시킨다.\n",
      "\n",
      "---\n",
      "\n",
      "### 5️⃣ 최종 배포와 추론 (Inference)\n",
      "\n",
      "| 요소 | 내용 |\n",
      "|------|------|\n",
      "| **온‑디바이스 vs 클라우드** | 대형 모델은 보통 클라우드 서버에서 실행되며, **API** 형태로 제공된다. |\n",
      "| **샘플링 기법** | **Greedy**, **Top‑k**, **Top‑p (nucleus)**, **Temperature** 등으로 다양하게 출력을 제어한다. |\n",
      "| **컨텍스트 윈도우** | 현재 GPT‑4 기준 8 k~32 k 토큰 정도의 컨텍스트를 한 번에 처리한다. |\n",
      "| **속도 최적화** | **FlashAttention**, **KV‑cache**, **양자화(Quantization)** 등을 활용해 레이턴시를 낮춘다. |\n",
      "\n",
      "---\n",
      "\n",
      "## 📚 요약\n",
      "\n",
      "1. **데이터 전처리** → 텍스트를 토큰화하고 정제한다.  \n",
      "2. **사전학습** → Transformer 기반 디코더가 “다음 토큰 예측”을 통해 대규모 텍스트 코퍼스로 학습한다.  \n",
      "3. **파인튜닝** → 특정 작업에 맞는 라벨링 데이터를 이용해 추가 학습한다.  \n",
      "4. **RLHF** → 인간 피드백을 보상 모델로 변환하고, 강화학습(PPO)으로 응답 품질·안전성을 높인다.  \n",
      "5. **추론** → 다양한 샘플링 기법과 최적화 기술로 실시간 대화 서비스를 제공한다.\n",
      "\n",
      "이러한 단계들을 거쳐 **ChatGPT**는 방대한 언어 지식과 대화 능력을 갖춘 모델이 되며, 사용자의 질문에 자연스럽고 유용한 답변을 생성할 수 있게 됩니다.\n"
     ]
    }
   ],
   "source": [
    "# 체인을 생성하여 호출하기\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "chain = chat_prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\"topic\":\"AI\", \"model_name\":\"ChatGPT\"})\n",
    "print(type(response))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) ChatPromptTemplate\n",
    "* SystemMessagePromptTemplate와 HumanMessagePromptTemplate 클래스 사용\n",
    "* 객체 지향적 접근 - Message 객체를 독립적으로 생성 가능\n",
    "* 여러 조건에 따라 다른 시스템 메시지 선택\n",
    "\n",
    "```python\n",
    "if user_is_beginner:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"초보자를 위한 설명: {topic}\")\n",
    "else:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"전문가를 위한 상세 분석: {topic}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatMessagePromptTemplate 활용\n",
    "\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    ChatMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 개별 메시지 템플릿 정의\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an AI expert in {topic}. Please provide clear and detailed explanations.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"This is an example answer about {topic}.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplate로 메시지들을 묶기\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# 메시지 생성\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"What is deep learning?\")\n",
    "\n",
    "# LLM 호출\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatMessagePromptTemplate는 여러 종류의 메시지(시스템, 인간, AI)를 조합하여 복잡한 프롬프트를 생성할 때 유용합니다.\n",
    "* SystemMessagePromptTemplate: 이 템플릿은 AI 모델에게 역할을 부여하거나 전반적인 규칙을 설정하는 시스템 메시지를 만듭니다. 위의 예시에서는 \"번역을 도와주는 유용한 도우미\"라는 역할을 지정합니다.\n",
    "* HumanMessagePromptTemplate: 이 템플릿은 사용자의 질문이나 요청을 담는 인간 메시지를 만듭니다. 아래의 예시에서는 번역할 텍스트를 입력받습니다.\n",
    "* ChatPromptTemplate.from_messages: 이 클래스 메서드는 시스템 메시지, 인간 메시지 등 여러 종류의 MessagePromptTemplate 객체들을 리스트로 받아 하나의 채팅 프롬프트 템플릿으로 통합합니다.\n",
    "* format_messages: 이 메서드는 정의된 템플릿에 실제 값을 채워 넣어 [SystemMessage, HumanMessage] 형태의 리스트를 반환합니다. 이 리스트는 채팅 모델(Chat Model) 에 바로 전달될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# 1. SystemMessagePromptTemplate와 HumanMessagePromptTemplate 생성\n",
    "# SystemMessagePromptTemplate는 모델의 페르소나 또는 기본 지침을 설정합니다.\n",
    "system_template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# HumanMessagePromptTemplate는 사용자로부터 받는 입력 프롬프트를 정의합니다.\n",
    "human_template = \"{text_to_translate}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# 2. ChatPromptTemplate 생성\n",
    "# 위에서 만든 두 템플릿을 리스트로 묶어 ChatPromptTemplate을 만듭니다.\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# 3. 프롬프트 포맷팅\n",
    "# chat_prompt_template.format_messages()를 사용하여 최종 메시지 리스트를 생성합니다.\n",
    "# 이 함수는 딕셔너리 형태의 입력 변수를 받습니다.\n",
    "formatted_prompt = chat_prompt_template.format_messages(\n",
    "    input_language=\"English\",\n",
    "    output_language=\"Korean\",\n",
    "    text_to_translate=\"I love programming.\"\n",
    ")\n",
    "\n",
    "# 4. 결과 출력\n",
    "print(formatted_prompt)\n",
    "\n",
    "# LLM 호출\n",
    "response = llm.invoke(formatted_prompt)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) FewShotPromptTemplate\n",
    "* FewShotPromptTemplate은 모델이 특정 형식을 따르게 하거나, 일관된 응답을 생성하도록 유도할 때 유용합니다.\n",
    "* 도메인 지식이 필요하거나, AI가 오답을 줄이고 더 신뢰할 만한 답변을 생성하도록 해야 할 때 효과적입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-1) PromptTemplate을 사용하지 않는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "태양계에는 8개의 행성이 있습니다. \n",
      "\n",
      "1.  수성: 태양과 가장 가까운 행성으로, 표면이 암석으로 구성되어 있고 극도로 높은 온도와 낮은 온도가 반복됩니다.\n",
      "2.  금성: 태양계에서 두 번째로 가까운 행성으로, 두꺼운 대기로 인해 극심한 온실 효과가 발생하여 매우 뜨겁습니다.\n",
      "3.  지구: 우리가 사는 행성으로, 물과 대기가 있어 생명체가 존재할 수 있습니다.\n",
      "4.  화성: 태양계에서 네 번째로 가까운 행성으로, 붉은색의 모래사막으로 덮여 있고 물과 생명체의 존재 가능성이 있습니다.\n",
      "5.  목성: 태양계에서 가장 큰 행성으로, 가스 거인이며 강력한 자기장과 수많은 위성을 가지고 있습니다.\n",
      "6.  토성: 태양계에서 두 번째로 큰 행성으로, 가스 거인이며 아름다운 고리를 가지고 있습니다.\n",
      "7.  천왕성: 태양계에서 일곱 번째로 가까운 행성으로, 가스 거인이며 자전축이 기울어져 있어 극단적인 기후 변화를 경험합니다.\n",
      "8.  해왕성: 태양계에서 가장 먼 행성으로, 가스 거인이며 강한 바람과 극적인 기후 변화를 가지고 있습니다.\n",
      "\n",
      "이러한 행성들은 각각 고유한 특징과 성질을 가지고 있으며, 태양계에서 중요한 역할을 합니다.\n"
     ]
    }
   ],
   "source": [
    "# PromptTemplate을 사용하지 않는 경우\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# chain 실행\n",
    "result = llm.invoke(\"태양계의 행성들을 간략히 정리해 주세요.\")\n",
    "\n",
    "print(type(result))\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-2) FewShotChatMessagePromptTemplate 사용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x0000022F394DF3B0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000022F391EDBB0> root_client=<openai.OpenAI object at 0x0000022F3651A360> root_async_client=<openai.AsyncOpenAI object at 0x0000022F3900CAA0> model_name='openai/gpt-oss-120b' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n",
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 초등학생도 쉽게 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.'), additional_kwargs={}), FewShotChatMessagePromptTemplate(examples=[{'input': '뉴턴의 운동 법칙을 요약해 주세요.', 'output': '### 뉴턴의 운동 법칙\\n1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\\n2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\\n3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.'}, {'input': '지구의 대기 구성 요소를 알려주세요.', 'output': '### 지구 대기의 구성\\n- **질소 (78%)**: 대기의 대부분을 차지합니다.\\n- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\\n- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\\n- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.'}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], input_types={}, partial_variables={}, template='{output}'), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[] last=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000022F394DF3B0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000022F391EDBB0>, root_client=<openai.OpenAI object at 0x0000022F3651A360>, root_async_client=<openai.AsyncOpenAI object at 0x0000022F3900CAA0>, model_name='openai/gpt-oss-120b', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "## 양자 컴퓨터가 뭐에요? – 초등학생도 이해할 수 있게 쉬게 설명해 볼게요  \n",
      "\n",
      "---\n",
      "\n",
      "### 1. 컴퓨터는 “정보”를 어떻게 저장하고 처리할까?  \n",
      "| 전통적인(클래식) 컴퓨터 | 양자 컴퓨터 |\n",
      "|------------------------|-------------|\n",
      "| **비트**라는 작은 스위치를 사용해요. 비트는 **0** 또는 **1** 중 하나만 가질 수 있어요. | **큐비트**라는 작은 입자를 사용해요. 큐비트는 **0**과 **1**을 동시에(‘두 가지 상태를 겹쳐서’) 가질 수 있어요. 이것을 **중첩(superposition)**이라고 불러요. |\n",
      "| 비트가 여러 개 모이면 2ⁿ가지 경우를 차례대로 계산해요. | 큐비트가 n개이면 한 번에 **2ⁿ가지** 경우를 동시에 살펴볼 수 있어요! (엄청 빠른 ‘동시 계산’) |\n",
      "\n",
      "---\n",
      "\n",
      "### 2. 양자 컴퓨터가 특별한 이유 3가지  \n",
      "\n",
      "| 1️⃣ 중첩 (Superposition) | **설명**: 큐비트는 0도 되고 1도 되는 동시에 ‘반반’ 상태가 될 수 있어요. <br>**비유**: 동전이 ‘앞면도 뒤면도 동시에 떠 있는’ 상태라고 생각하면 쉬워요! |\n",
      "|---|---|\n",
      "| 2️⃣ 얽힘 (Entanglement) | **설명**: 두 개 이상의 큐비트가 서로 ‘손을 잡고’ 움직이면, 한 큐비트가 어떻게 변하든 다른 큐비트도 바로 그에 맞게 변해요. <br>**비유**: 쌍둥이 형제가 눈을 맞추면 한 명이 웃으면 다른 사람도 바로 웃는 것과 비슷해요. |\n",
      "| 3️⃣ 양자 터널링 (Quantum Tunneling) | **설명**: 입자는 ‘장벽’(막)을 뚫고 지나갈 수 있어요. 이것을 이용해 계산을 아주 빠르게 찾아낼 수 있어요. <br>**비유**: 마치 작은 공이 높은 울타리를 뛰어넘지 못하지만, 마법처럼 울타리 뒤로 살금살금 들어가는 느낌! |\n",
      "\n",
      "---\n",
      "\n",
      "### 3. 양자 컴퓨터가 잘 하는 일 (예시)\n",
      "\n",
      "| 분야 | 왜 양자 컴퓨터가 유리할까? |\n",
      "|------|------------------------------|\n",
      "| **암호 해독** | 현재 쓰는 비밀키(암호)를 아주 빠르게 찾아낼 수 있어요. (하지만 동시에 보안도 더 강하게 만들 필요가 있어요) |\n",
      "| **신약·신소재 설계** | 분자(원자)들의 복잡한 움직임을 한 번에 시뮬레이션해서 새로운 약이나 재료를 빠르게 찾을 수 있어요. |\n",
      "| **최적화 문제** | 물류 배달 경로나 게임 퍼즐 같은 ‘가장 좋은 방법’ 찾기를 엄청 빠르게 할 수 있어요. |\n",
      "| **인공지능** | 양자 알고리즘으로 데이터를 더 효율적으로 배우게 할 수 있는 가능성이 있어요. |\n",
      "\n",
      "---\n",
      "\n",
      "### 4. 아직은 ‘아직 멀었어요’  \n",
      "\n",
      "* **아주 차가운 온도**: 양자 컴퓨터는 거의 절대 영도(‑273 ℃)에 가까운 초저온에서만 작동해요.  \n",
      "* **오류가 많이 생겨요**: 작은 방해(소음)에도 큐비트가 엉망이 될 수 있어서 ‘오류 교정’ 기술이 필요해요.  \n",
      "* **특정 문제에만 강해요**: 모든 일을 클래식 컴퓨터보다 빠르게 할 수 있는 건 아니에요. ‘특별한 문제’에 강점이 있어요.\n",
      "\n",
      "---\n",
      "\n",
      "### 5. 한 마디 요약  \n",
      "\n",
      "> **양자 컴퓨터는 ‘0과 1을 동시에 쓰는 마법의 비트(큐비트)’와 ‘서로 손잡고 움직이는 얽힌 입자’를 이용해서, 어떤 복잡한 문제를 아주 빠르게 풀어내는 새로운 종류의 컴퓨터예요. 아직은 실험실 단계지만, 앞으로 과학·의학·보안·인공지능 등 여러 분야를 크게 바꿀 잠재력이 있어요!**\n",
      "\n",
      "---\n",
      "\n",
      "#### 🌟 기억해 두면 좋은 포인트\n",
      "1. **비트 vs 큐비트** – 0 or 1 vs 0 + 1 동시에.  \n",
      "2. **중첩 + 얽힘** = ‘많은 경우를 한 번에 계산하는 힘’.  \n",
      "3. **아직은 어려운 기술** → 앞으로 더 발전할 거예요!  \n",
      "\n",
      "궁금한 점이 있으면 언제든 물어보세요! 🚀\n"
     ]
    }
   ],
   "source": [
    "# FewShotChatMessagePromptTemplate 사용하는 경우\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"뉴턴의 운동 법칙을 요약해 주세요.\",\n",
    "        \"output\": \"\"\"### 뉴턴의 운동 법칙\n",
    "1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\n",
    "2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\n",
    "3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"지구의 대기 구성 요소를 알려주세요.\",\n",
    "        \"output\": \"\"\"### 지구 대기의 구성\n",
    "- **질소 (78%)**: 대기의 대부분을 차지합니다.\n",
    "- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\n",
    "- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\n",
    "- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 예제 프롬프트 템플릿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate 적용\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# 최종 프롬프트 구성\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 초등학생도 쉽게 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 모델 생성 및 체인 구성\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "chain = final_prompt | llm\n",
    "print(llm)\n",
    "print(chain)\n",
    "\n",
    "# 테스트 실행\n",
    "result = chain.invoke({\"input\": \"양자컴퓨터 정리해 주세요.\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-1) PartialPrompt \n",
    "* 프롬프트를 더 동적으로 활용할 수 있으며, AI 응답을 더 일관성 있게 조정 가능함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 계절을 결정하는 함수 (남반구/북반구 고려)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # 북반구 (기본값)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"봄\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"여름\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"가을\"\n",
    "        else:\n",
    "            return \"겨울\"\n",
    "    else:  # 남반구 (계절 반대)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"가을\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"겨울\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"봄\"\n",
    "        else:\n",
    "            return \"여름\"\n",
    "\n",
    "# 프롬프트 템플릿 정의 (부분 변수 적용)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{season}에 일어나는 대표적인 지구과학 현상은 {phenomenon}이 맞나요? {season}에 주로 발생하는 지구과학 현상을 3개 알려주세요\",\n",
    "    input_variables=[\"phenomenon\"],  # 사용자 입력 필요\n",
    "    partial_variables={\"season\": get_current_season()}  # 동적으로 계절 값 할당\n",
    ")\n",
    "\n",
    "# OpenAI 모델 초기화\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "\n",
    "# 특정 계절의 현상 질의\n",
    "query = prompt.format(phenomenon=\"태풍 발생\")\n",
    "result = llm.invoke(query)\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "print(f\" 프롬프트: {query}\")\n",
    "print(f\" 모델 응답: {result.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 계절: 가을\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 계절을 결정하는 함수 (남반구/북반구 고려)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # 북반구 (기본값)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"봄\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"여름\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"가을\"\n",
    "        else:\n",
    "            return \"겨울\"\n",
    "    else:  # 남반구 (계절 반대)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"가을\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"겨울\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"봄\"\n",
    "        else:\n",
    "            return \"여름\"\n",
    "\n",
    "# Step 1: 현재 계절 결정\n",
    "season_name = get_current_season(\"north\")  # 계절 값 얻기\n",
    "print(f\"현재 계절: {season_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 가을에 발생하는 자연 현상:\n",
      "### 가을에 주로 나타나는 대표적인 지구과학 현상 3가지  \n",
      "\n",
      "| 현상 | 간단한 설명 |\n",
      "|------|-------------|\n",
      "| **1. 낙엽 색 변화·낙엽 (Leaf Senescence)** | 가을이 되면 낮이 짧아지고 기온이 낮아지면서 식물은 광합성에 필요한 엽록소를 분해한다. 이때 잎에 있던 카로티노이드·안토시아닌 색소가 드러나면서 빨강·노랑·주황색으로 물들고, 결국 잎이 떨어진다. 이는 **식물 생태·기후 변화를 기록하는 중요한 지표**가 된다. |\n",
      "| **2. 기온 역전 현상 (Temperature Inversion)** | 가을 밤에는 땅이 급격히 식으면서 지표면 가까이의 공기가 차가워지고, 위쪽 고도에서는 아직 따뜻한 공기가 남는다. 이렇게 **따뜻한 공기가 차가운 공기 위에 얹히는 현상**이 발생하면, 대기 중 오염물질·수증기가 하층에 머물게 되어 안개·스모그가 자주 나타난다. 특히 산골이나 계곡 지역에서 흔히 관측된다. |\n",
      "| **3. 제트기류 남하·중위도 저기압 활동 증가** | 가을이 되면 **극지방과 열대 지방 사이의 온도 차이가 커지면서 제트기류가 남쪽(중위도)으로 이동**한다. 이로 인해 중위도 지역에 저기압(저기압성 저기압)과 전선이 자주 통과해 **강한 바람·폭우·한랭 전선**이 나타난다. 한국·동아시아에서는 가을철 장마가 끝난 뒤에도 한두 차례 “가을 폭풍”이 찾아오는 것이 이 메커니즘과 관련된다. |\n",
      "\n",
      "> **요약**  \n",
      "> - **낙엽 색 변화**는 식물 내부 화학 변화가 기후와 연동된 현상.  \n",
      "> - **기온 역전**은 지표면 냉각으로 인한 대기 안정화 현상으로 안개·스모그를 유발.  \n",
      "> - **제트기류 남하**와 그에 따른 **중위도 저기압·폭풍**은 가을 대기의 전반적인 흐름 변화를 보여준다.  \n",
      "\n",
      "이 세 가지 현상은 가을에 특히 뚜렷하게 나타나며, 기후·환경 모니터링 및 재해 대비에 중요한 역할을 합니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: 해당 계절의 자연 현상 추천\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"{season}에 주로 발생하는 대표적인 지구과학 현상 3가지를 알려주세요. \"\n",
    "    \"각 현상에 대해 간단한 설명을 포함해주세요.\"\n",
    ")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "# llm = ChatOpenAI(\n",
    "#     #api_key=OPENAI_API_KEY,\n",
    "#     base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "#     model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "#     temperature=0.0\n",
    "# )\n",
    "\n",
    "# 체인 2: 자연 현상 추천 (입력: 계절 → 출력: 자연 현상 목록)\n",
    "chain2 = (\n",
    "    {\"season\": lambda x : season_name}  # chain1의 출력을 season 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 실행: 현재 계절에 따른 자연 현상 추천\n",
    "response = chain2.invoke({})\n",
    "print(f\"\\n {season_name}에 발생하는 자연 현상:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-2) PartialPrompt \n",
    "* API 호출 데이터, 시간 정보, 사용자 정보 등을 반영할 때 매우 유용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 프롬프트: 현재 1달러 = 1377.98원 기준으로 환율 정보를 알려드립니다. 이에 대한 분석을 제공해 주세요.\n",
      " 모델 응답: ### 1 USD = 1 377.98 KRW 환율에 대한 종합 분석  \n",
      "\n",
      "---\n",
      "\n",
      "## 1. 현재 환율이 의미하는 바\n",
      "\n",
      "| 구분 | 내용 |\n",
      "|------|------|\n",
      "| **명목 환율** | 1 USD = 1 377.98 KRW (2025‑09‑18 기준) |\n",
      "| **전년 동월 대비** | 약 +3 ~ 4 % 상승 (2024‑09 기준 1 332 ~ 1 350 KRW 수준) |\n",
      "| **주요 요인** | - 미국 연방준비제도(Fed)의 금리 인상 지속 <br> - 한국은행(BOK)의 금리 인하·완화 기대감 <br> - 글로벌 위험 회피 심리(미·중 갈등, 유가 변동) <br> - 원달러 스와프·외환시장 개입 가능성 감소 |\n",
      "\n",
      "> **핵심 포인트**: 현재 원화는 **달러 대비 약 3–4 % 절하**된 상태이며, 이는 2023년 말부터 이어진 ‘달러 강세 흐름’이 지속되고 있음을 보여줍니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. 역사적 흐름과 비교\n",
      "\n",
      "| 연도 | 평균 환율 (KRW/USD) | 주요 사건 |\n",
      "|------|-------------------|-----------|\n",
      "| 2020 | 1 180 ~ 1 210 | 코로나19 초기, 달러 약세 |\n",
      "| 2021 | 1 150 ~ 1 200 | 경기 회복, 달러 약세 지속 |\n",
      "| 2022 | 1 200 ~ 1 300 | 러시아-우크라이나 전쟁, 달러 급등 |\n",
      "| 2023 | 1 300 ~ 1 350 | Fed 연속 금리 인상, 원화 지속 약세 |\n",
      "| 2024 | 1 330 ~ 1 350 | 금리 인상 둔화, 원화 회복 시도 |\n",
      "| **2025** | **1 378** (현재) | **달러 강세 지속, 원화 추가 약세** |\n",
      "\n",
      "* **장기 평균**(2000‑2025) ≈ 1 150 KRW/USD  \n",
      "* 현재 수준은 **역사적 평균보다 약 20 % 이상 고평가**된 상황이며, 2008년 금융위기 시점(≈1 500 KRW/USD)과도 근접합니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. 주요 경제 주체별 영향\n",
      "\n",
      "| 주체 | 긍정적 효과 | 부정적 효과 |\n",
      "|------|------------|------------|\n",
      "| **수출기업** (반도체, 자동차, 조선 등) | - 원화 약세 → 해외 매출·수익 증가 <br> - 경쟁력 상승 (가격 경쟁력) | - 원자재·부품을 해외에서 조달 시 비용 상승 (특히 미국·유럽 공급) |\n",
      "| **수입기업** (에너지, 원자재, 반도체 장비) | - 일부 비달러(위안·엔) 결제는 영향 적음 | - 수입 원가 상승 → 마진 압박 <br> - 물가 전가로 인한 소비자 가격 상승 |\n",
      "| **소비자** | - 해외 여행·온라인 쇼핑 비용 상승 억제 (여행 감소) | - 수입품·외식·에너지 가격 상승 → 생활비 증가 |\n",
      "| **투자자·기업** | - 해외 자산(달러표시) 보유 시 평가이익 | - 외채·채권 상환 부담 확대 <br> - 환위험 헤지 비용 상승 |\n",
      "| **관광·여행업** | - 국내 관광 증가 (해외 여행 비용 상승) | - 외국인 관광객 유입 감소 (원화 고가) |\n",
      "\n",
      "> **요약**: 원화 약세는 **수출 중심 기업**에 유리하지만, **수입·소비·외채**에 큰 부담을 주는 구조적 양면성을 가집니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 4. 물가·통화정책에 미치는 파급 효과\n",
      "\n",
      "1. **수입 물가 상승**  \n",
      "   - 원자재·에너지(특히 석유·가스) 가격이 달러 기준으로 유지될 경우, 원화 약세는 **수입 물가 상승**을 초래합니다.  \n",
      "   - 2025년 현재 한국의 **핵심 인플레이션**은 2.7 % 수준이며, 원화 약세가 지속될 경우 0.3 ~ 0.5 %p 상승 압력이 예상됩니다.\n",
      "\n",
      "2. **한국은행(BOK) 통화정책**  \n",
      "   - 인플레이션 상승 압력과 경기 부양 필요성 사이에서 **정책 딜레마**가 발생합니다.  \n",
      "   - 현재 기준금리(3.5 %)는 **완화 기조**에 가깝지만, 물가 상승이 가속화될 경우 **금리 인상** 가능성이 있습니다.\n",
      "\n",
      "3. **외환시장 안정성**  \n",
      "   - 급격한 원달러 변동성은 **스와프·외환시장 개입** 압력을 높일 수 있습니다.  \n",
      "   - 최근 BOE(한국은행)와 미국 연방준비제도 간 **스와프 라인** 활용이 감소하면서 시장 자체 조정 메커니즘에 의존하고 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 5. 전망 시나리오 (2025‑2027)\n",
      "\n",
      "| 시나리오 | 주요 가정 | 예상 환율(USD/KRW) | 핵심 파급 효과 |\n",
      "|----------|-----------|--------------------|----------------|\n",
      "| **베이스** | - Fed 금리 동결 후 점진적 인하 <br> - 한국 경제 회복세 지속, 수출 호조 | 1 350 ~ 1 380 | 수출기업 지속 호조, 물가 상승 억제·완화 |\n",
      "| **달러 강세 지속** | - 미국 경기 회복·인플레이션 재점화 → 금리 추가 인상 <br> - 한국 내외부 리스크(지정학·에너지) 확대 | 1 420 ~ 1 470 | 수입물가 급등, 인플레이션 3 % 이상, BOK 금리 인상 압력 |\n",
      "| **원화 회복** | - 한국의 금리 인상·외채 감소 <br> - 글로벌 위험 회피 감소, 달러 수요 둔화 | 1 250 ~ 1 300 | 수입기업 비용 절감, 소비자 물가 안정, 해외 관광 회복 |\n",
      "\n",
      "> **가장 가능성 높은 시나리오**는 ‘베이스’이며, **Fed가 금리 동결·점진 인하**하고 **한국경제가 회복**될 경우 현재 수준(1 378 KRW/USD)에서 **소폭 절하** 혹은 **안정**될 전망입니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 6. 기업·투자자를 위한 실무적 시사점\n",
      "\n",
      "| 분야 | 권고 조치 |\n",
      "|------|-----------|\n",
      "| **환위험 관리** | - **선물·옵션**을 활용한 헤지 비중 확대 (특히 6~12개월 선물) <br> - **통화 스와프** 계약 검토 (달러·원) |\n",
      "| **수출기업** | - **가격전략**: 원화 약세를 반영한 가격 인상 가능성 검토 <br> - **다변화**: 주요 고객 포트폴리오를 **달러·위안·엔** 등 다통화로 확대 |\n",
      "| **수입기업** | - **공급망 재조정**: 원자재를 **원화 결제** 가능한 공급처(아시아)로 전환 <br> - **재고 확보**: 환율 급등기에 대비해 **재고 선구매** 전략 |\n",
      "| **투자자** | - **달러 자산 비중**: 원화 약세 지속 시 **달러채권·ETF** 비중 확대 고려 <br> - **원화 고수익 채권**: 금리 차익을 활용한 **KRW 고수익 채권**(예: 기업채) 투자 검토 |\n",
      "| **소비자** | - **외화예금·달러 적립**: 환율 상승 시점에 **달러 예금**을 통한 자산 다변화 <br> - **대체 소비**: 수입품 대신 **국산·대체품** 구매 확대 |\n",
      "\n",
      "> **주의**: 위 권고는 일반적인 가이드라인이며, 개인·기업별 상황에 따라 위험도가 다를 수 있습니다. 반드시 자체 위험 평가와 전문가 상담을 병행하시기 바랍니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 7. 결론\n",
      "\n",
      "- **현재 1 USD = 1 377.98 KRW**는 **역사적으로 높은 수준**이며, 달러 강세가 지속될 경우 한국 경제 전반에 **수입 물가 상승·인플레이션 압력**을 가중시킬 가능성이 큽니다.  \n",
      "- **수출기업**은 환율 상승을 기회로 활용할 수 있지만, **수입기업·소비자**는 비용 상승 부담을 겪게 됩니다.  \n",
      "- **통화정책**은 인플레이션과 경기 회복 사이에서 균형을 맞추려 할 것이며, **환율 변동성**이 커질 경우 중앙은행의 시장 개입 가능성도 배제할 수 없습니다.  \n",
      "- **전망**은 미국 금리 정책과 한국 경제 회복 속도에 크게 좌우되며, **베이스 시나리오**(1 350 ~ 1 380) 정도가 가장 현실적인 범위로 보입니다.  \n",
      "\n",
      "**전략적 대응**을 위해서는 **환위험 헤지**와 **다통화·다지역 공급망·투자 포트폴리오** 구축이 핵심이며, 시장 변동성을 면밀히 모니터링하면서 유연하게 정책을 조정하는 것이 필요합니다.  \n",
      "\n",
      "---  \n",
      "\n",
      "*본 분석은 공개된 시장 데이터와 일반적인 경제 이론에 기반한 것이며, 구체적인 투자·거래 결정을 위한 최종 판단은 별도의 전문 상담을 권고합니다.*\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 실시간 환율을 가져오는 함수\n",
    "def get_exchange_rate():\n",
    "    response = requests.get(\"https://api.exchangerate-api.com/v4/latest/USD\")\n",
    "    data = response.json()\n",
    "    return f\"1달러 = {data['rates']['KRW']}원\"\n",
    "\n",
    "# Partial Prompt 활용\n",
    "prompt = PromptTemplate(\n",
    "    template=\"현재 {info} 기준으로 환율 정보를 알려드립니다. 이에 대한 분석을 제공해 주세요.\",\n",
    "    input_variables=[],  # 사용자 입력 없음\n",
    "    partial_variables={\"info\": get_exchange_rate()}  # API에서 가져온 데이터 자동 반영\n",
    ")\n",
    "\n",
    "# LLM 모델 설정\n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "# 모델에 프롬프트 전달 및 응답 받기\n",
    "response = llm.invoke(prompt.format())\n",
    "\n",
    "# 결과 출력\n",
    "print(\" 프롬프트:\", prompt.format())\n",
    "print(\" 모델 응답:\", response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
