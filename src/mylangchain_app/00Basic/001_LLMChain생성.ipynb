{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a",
   "metadata": {
    "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a"
   },
   "source": [
    "### LLM Chain 만들기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9",
   "metadata": {
    "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9"
   },
   "source": [
    "## 1. 환경 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81",
   "metadata": {
    "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81"
   },
   "source": [
    "### 1) 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
    "outputId": "c96ed02d-19b7-4e90-d92e-1ae52895e303"
   },
   "outputs": [],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55152049-e9e5-4952-8e19-409f58cf3ac9",
   "metadata": {
    "id": "55152049-e9e5-4952-8e19-409f58cf3ac9"
   },
   "source": [
    "### 2) OpenAI 인증키 설정\n",
    "https://openai.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b76f68a8-4745-4377-8057-6090b87377d1",
   "metadata": {
    "id": "b76f68a8-4745-4377-8057-6090b87377d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_w\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e09aaca6-5aa2-4b52-bbfc-196e808dc5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.27\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c",
   "metadata": {
    "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c"
   },
   "source": [
    "## 2. LLM Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23729d10-9600-415b-b7d1-f954665224e3",
   "metadata": {
    "id": "23729d10-9600-415b-b7d1-f954665224e3"
   },
   "source": [
    "### 1) Prompt + LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "on0y4xF8VoyE",
   "metadata": {
    "id": "on0y4xF8VoyE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 실행\n",
    "result = llm.invoke(\"인공지능 모델의 학습 원리에 대하여 쉽게 설명해 주세요.\")\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dc4accf-c927-40a3-ba2c-f891c94c34f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='인공지능 모델의 학습 원리는 다음과 같습니다.\\n\\n1. **데이터 수집** : 인공지능 모델은 학습을 위해 대량의 데이터를 수집합니다. 이 데이터는 모델이 학습할 수 있는 형태로 가공되어 있어야 합니다.\\n\\n2. **데이터 전처리** : 수집된 데이터는 전처리 과정을 거칩니다. 이 과정에서는 데이터의 품질을 높이고, 모델에 적합한 형태로 변환합니다.\\n\\n3. **모델 정의** : 인공지능 모델은 수학적 함수로 정의됩니다. 이 함수는 입력 데이터와 출력 데이터 사이의 관계를 나타냅니다.\\n\\n4. **손실 함수 정의** : 손실 함수는 모델의 예측 결과와 실제 결과 사이의 차이를 측정합니다. 모델의 목표는 이 손실 함수를 최소화하는 것입니다.\\n\\n5. **최적화 알고리즘** : 최적화 알고리즘은 모델의 매개변수를 조정하여 손실 함수를 최소화합니다. 대표적인 최적화 알고리즘에는 경사 하강법(Gradient Descent), Adam, RMSProp 등이 있습니다.\\n\\n6. **학습** : 모델은 최적화 알고리즘을 사용하여 학습 데이터를 반복적으로 처리합니다. 이 과정에서 모델의 매개변수가 조정되어 손실 함수가 최소화됩니다.\\n\\n7. **평가** : 학습이 완료되면, 모델은 테스트 데이터를 사용하여 평가됩니다. 이 평가를 통해 모델의 성능을 측정하고, 추가적인 조정이 필요한지 판단합니다.\\n\\n예를 들어, 이미지 분류 모델을 학습하는 경우를 생각해 봅시다. 이 모델은 이미지 데이터를 입력으로 받아서, 해당 이미지의 카테고리를 출력으로 내보냅니다. 모델은 대량의 이미지 데이터를 수집하고, 이를 전처리하여 학습에 적합한 형태로 변환합니다. 그런 다음, 모델은 손실 함수를 정의하고, 최적화 알고리즘을 사용하여 학습 데이터를 반복적으로 처리합니다. 이 과정에서 모델의 매개변수가 조정되어 손실 함수가 최소화됩니다. 학습이 완료되면, 모델은 테스트 데이터를 사용하여 평가됩니다.\\n\\n이러한 학습 원리는 다양한 인공지능 모델에 적용될 수 있습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 394, 'prompt_tokens': 24, 'total_tokens': 418, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.791912824, 'prompt_time': 0.00048118, 'completion_time': 1.001932964, 'total_time': 1.002414144}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_5d3e4e58e1', 'id': 'chatcmpl-cfeeba9f-baba-47be-98f5-233f688e73aa', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--3e992d7d-0182-4ff5-a734-5ada4d6075e7-0' usage_metadata={'input_tokens': 24, 'output_tokens': 394, 'total_tokens': 418, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "WzcZy4PruV1n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "WzcZy4PruV1n",
    "outputId": "18ecc8f9-5748-4b16-cb07-4a0f7a01fb5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 다음과 같습니다.\n",
      "\n",
      "1. **데이터 수집** : 인공지능 모델은 학습을 위해 대량의 데이터를 수집합니다. 이 데이터는 모델이 학습할 수 있는 형태로 가공되어 있어야 합니다.\n",
      "\n",
      "2. **데이터 전처리** : 수집된 데이터는 전처리 과정을 거칩니다. 이 과정에서는 데이터의 품질을 높이고, 모델에 적합한 형태로 변환합니다.\n",
      "\n",
      "3. **모델 정의** : 인공지능 모델은 수학적 함수로 정의됩니다. 이 함수는 입력 데이터와 출력 데이터 사이의 관계를 나타냅니다.\n",
      "\n",
      "4. **손실 함수 정의** : 손실 함수는 모델의 예측 결과와 실제 결과 사이의 차이를 측정합니다. 모델의 목표는 이 손실 함수를 최소화하는 것입니다.\n",
      "\n",
      "5. **최적화 알고리즘** : 최적화 알고리즘은 모델의 매개변수를 조정하여 손실 함수를 최소화합니다. 대표적인 최적화 알고리즘에는 경사 하강법(Gradient Descent), Adam, RMSProp 등이 있습니다.\n",
      "\n",
      "6. **학습** : 모델은 최적화 알고리즘을 사용하여 학습 데이터를 반복적으로 처리합니다. 이 과정에서 모델의 매개변수가 조정되어 손실 함수가 최소화됩니다.\n",
      "\n",
      "7. **평가** : 학습이 완료되면, 모델은 테스트 데이터를 사용하여 평가됩니다. 이 평가를 통해 모델의 성능을 측정하고, 추가적인 조정이 필요한지 판단합니다.\n",
      "\n",
      "예를 들어, 이미지 분류 모델을 학습하는 경우를 생각해 봅시다. 이 모델은 이미지 데이터를 입력으로 받아서, 해당 이미지의 카테고리를 출력으로 내보냅니다. 모델은 대량의 이미지 데이터를 수집하고, 이를 전처리하여 학습에 적합한 형태로 변환합니다. 그런 다음, 모델은 손실 함수를 정의하고, 최적화 알고리즘을 사용하여 학습 데이터를 반복적으로 처리합니다. 이 과정에서 모델의 매개변수가 조정되어 손실 함수가 최소화됩니다. 학습이 완료되면, 모델은 테스트 데이터를 사용하여 평가됩니다.\n",
      "\n",
      "이러한 학습 원리는 다양한 인공지능 모델에 적용될 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c97fc",
   "metadata": {},
   "source": [
    "### 2) PromptTemplate + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "SeNi_VXqYD-b",
   "metadata": {
    "id": "SeNi_VXqYD-b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.prompt.PromptTemplate'>\n",
      "input_variables=['input'] input_types={} partial_variables={} template='You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01WLucSpYjZt",
   "metadata": {
    "id": "01WLucSpYjZt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 방식과 유사합니다. 컴퓨터가 데이터를 통해 스스로 학습하고, 주어진 문제에 대한 해결 능력을 키우는 과정이라고 할 수 있습니다.\\n\\n예를 들어, 어린아이가 고양이를 인식하는 법을 배우는 과정을 생각해 보겠습니다. 처음에 아이는 고양이를 볼 때마다 \"고양이\"라는 단어를 듣고, 그 모습을 기억합니다. 시간이 지남에 따라, 아이는 고양이의 특징들 (예: 털이 있다, 작다, 울음 소리가 난다)을 학습하고, 고양이를 더 잘 인식하게 됩니다.\\n\\n인공지능 모델도 이와 비슷한 원리로 학습합니다. 컴퓨터에 많은 데이터를 주고, 그 데이터를 통해 모델이 스스로 규칙을 찾고, 패턴을 인식하도록 하는 것입니다. 이 과정을 통해 모델은 주어진 문제에 대해 더 정확하게 예측하거나 분류할 수 있게 됩니다.\\n\\n구체적으로는, 인공지능 모델의 학습 과정은 다음과 같습니다:\\n\\n1. **데이터 수집**: 인공지능 모델을 학습시키기 위해 필요한 데이터를 수집합니다.\\n2. **데이터 전처리**: 수집한 데이터를 모델이 학습할 수 있도록 가공합니다.\\n3. **모델 훈련**: 모델이 데이터를 학습하고, 규칙을 찾고, 패턴을 인식하도록 합니다.\\n4. **모델 평가**: 모델의 성능을 평가하고, 필요에 따라 모델을 수정하거나 개선합니다.\\n\\n이렇게 인공지능 모델은 데이터를 통해 학습하고, 주어진 문제에 대한 해결 능력을 키우게 됩니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 303, 'prompt_tokens': 36, 'total_tokens': 339, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.205758401, 'prompt_time': 0.000838196, 'completion_time': 0.731204901, 'total_time': 0.732043097}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_37da608fc1', 'id': 'chatcmpl-da0a49fb-5399-4ad3-b1a1-4a99a2c0d78d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--55e845d4-f143-4141-b3ab-e709ff0c9672-0' usage_metadata={'input_tokens': 36, 'output_tokens': 303, 'total_tokens': 339, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm\n",
    "print(type(chain))\n",
    "\n",
    "# chain 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "170ec878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 방식과 유사합니다. 컴퓨터가 데이터를 통해 스스로 학습하고, 주어진 문제에 대한 해결 능력을 키우는 과정이라고 할 수 있습니다.\n",
      "\n",
      "예를 들어, 어린아이가 고양이를 인식하는 법을 배우는 과정을 생각해 보겠습니다. 처음에 아이는 고양이를 볼 때마다 \"고양이\"라는 단어를 듣고, 그 모습을 기억합니다. 시간이 지남에 따라, 아이는 고양이의 특징들 (예: 털이 있다, 작다, 울음 소리가 난다)을 학습하고, 고양이를 더 잘 인식하게 됩니다.\n",
      "\n",
      "인공지능 모델도 이와 비슷한 원리로 학습합니다. 컴퓨터에 많은 데이터를 주고, 그 데이터를 통해 모델이 스스로 규칙을 찾고, 패턴을 인식하도록 하는 것입니다. 이 과정을 통해 모델은 주어진 문제에 대해 더 정확하게 예측하거나 분류할 수 있게 됩니다.\n",
      "\n",
      "구체적으로는, 인공지능 모델의 학습 과정은 다음과 같습니다:\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델을 학습시키기 위해 필요한 데이터를 수집합니다.\n",
      "2. **데이터 전처리**: 수집한 데이터를 모델이 학습할 수 있도록 가공합니다.\n",
      "3. **모델 훈련**: 모델이 데이터를 학습하고, 규칙을 찾고, 패턴을 인식하도록 합니다.\n",
      "4. **모델 평가**: 모델의 성능을 평가하고, 필요에 따라 모델을 수정하거나 개선합니다.\n",
      "\n",
      "이렇게 인공지능 모델은 데이터를 통해 학습하고, 주어진 문제에 대한 해결 능력을 키우게 됩니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56848a4c",
   "metadata": {},
   "source": [
    "### 3) PromptTemplate + LLM(invoke()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d1e9009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'str'>\n",
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. \n",
      "\n",
      "기본적으로 인공지능 모델은 데이터를 통해 학습합니다. 예를 들어, 고양이와 강아지의 사진을 보여주며 \"이것은 고양이야\", \"이것은 강아지야\"라고 말해주는 것과 같습니다. 인공지능 모델은 이러한 데이터를 통해 패턴을 찾고, 고양이와 강아지를 구별하는 법을 배웁니다.\n",
      "\n",
      "구체적으로는 다음과 같은 과정으로 학습합니다.\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델을 학습시키기 위해 필요한 데이터를 수집합니다. 예를 들어, 고양이와 강아지의 사진 데이터입니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집한 데이터를 모델이 처리할 수 있도록 변환하는 과정입니다. 예를 들어, 이미지 데이터를 픽셀 값으로 변환하는 것입니다.\n",
      "\n",
      "3. **모델 훈련**: 데이터를 모델에 입력하고, 모델이 데이터를 분석하여 결과를 예측합니다. 이때, 모델은 예측 결과와 실제 값 사이의 오류를 계산합니다.\n",
      "\n",
      "4. **오류 최소화**: 모델은 오류를 최소화하기 위해 가중치를 조정합니다. 이 과정은 반복적으로 이루어지며, 모델의 성능이 개선됩니다.\n",
      "\n",
      "5. **모델 평가**: 학습이 완료된 후, 모델의 성능을 평가합니다. 평가 데이터에 대해 모델의 예측 결과가 얼마나 정확한지 확인합니다.\n",
      "\n",
      "6. **모델 배포**: 모델의 성능이 만족할 만한 수준이면, 실제 환경에 배포하여 사용할 수 있습니다.\n",
      "\n",
      "이러한 학습 과정을 통해 인공지능 모델은 데이터로부터 패턴을 학습하고, 새로운 데이터에 대해 예측할 수 있는 능력을 갖추게 됩니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. \\\n",
    "                                       Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 2. chain 생성 (LCEL)\n",
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "\n",
    "# 3. chain의 invoke 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d997b16",
   "metadata": {},
   "source": [
    "### 4) PromptTemplate + LLM(stream()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "684654e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. \n",
      "\n",
      "1. **데이터 수집**: 우선 인공지능이 학습할 데이터를 수집합니다. 예를 들어, 고양이와 강아지의 사진을 인공지능에게 보여주고 싶으면, 수많은 고양이와 강아지의 사진을 모아야 합니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집한 데이터를 인공지능이 이해할 수 있도록 숫자의 형태로 변환하는 과정을 거칩니다.\n",
      "\n",
      "3. **모델 설계**: 인공지능 모델을 설계합니다. 모델은 입력된 데이터를 바탕으로 예측이나 분류를 수행하는 알고리즘입니다.\n",
      "\n",
      "4. **학습**: 모델에 데이터를 입력하고, 실제 결과와 예측 결과를 비교합니다. 이 과정에서 모델은 스스로 결과를 예측하기 위해 내부적인 계산 방법(가중치와 편향)을 조금씩 수정해 나갑니다. 이 과정을 여러 번 반복하면서 모델의 정확도가 높아집니다.\n",
      "\n",
      "5. **평가**: 학습이 완료된 후, 모델의 성능을 평가합니다. 평가 데이터 세트를 사용하여 모델의 예측 정확도를 확인하고, 필요에 따라 모델을 수정하거나 학습을 추가로 진행합니다.\n",
      "\n",
      "예를 들어, **선형 회귀** 모델을 설계하여 주택의 크기와 가격 간의 관계를 학습하는 경우를 생각해 봅시다. \n",
      "\n",
      "- 데이터를 수집하고 전처리합니다. (예: 주택 크기, 가격)\n",
      "- 모델에 주택 크기를 입력하고, 모델이 예측한 가격과 실제 가격을 비교합니다.\n",
      "- 모델은 예측 오류를 줄이기 위해 내부 파라미터를 조정합니다. (예: 가중치와 편향)\n",
      "- 이 과정을 반복하면서 모델은 주택 크기와 가격 간의 관계를 학습하고, 새로운 주택의 크기가 주어졌을 때 가격을 예측할 수 있게 됩니다.\n",
      "\n",
      "이와 같은 원리로 인공지능 모델은 데이터를 통해 학습하고, 주어진 문제에 대해 예측하거나 분류하는 능력을 키우게 됩니다."
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "lm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "# 스트리밍 출력\n",
    "#print(answer)\n",
    "\n",
    "for token in answer:\n",
    "    # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0188674-915f-41af-ac46-56f9f54289b0",
   "metadata": {
    "id": "b0188674-915f-41af-ac46-56f9f54289b0"
   },
   "source": [
    "##### 2) Multiple Chains\n",
    "* Multi Chain을 활용한 영화 추천 및 줄거리 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
    "outputId": "7ee83878-5d1a-45e3-f033-100da33f3ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      " ===> 추천된 영화:\n",
      "**『쇼생크 탈출(The Shawshank Redemption, 1994)』**을 꼽고 싶습니다.  \n",
      "감옥이라는 극한 공간에서 희망·우정·자유를 그린 ‘인생 드라마’의 끝판왕이죠. 한 편만 봐도 눈물과 울림, 그리고 삶에 대한 믿음이 생깁니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "movie = chain1.invoke({\"genre\": \"Drama\"})  # 영화 제목 얻기\n",
    "\n",
    "print(type(movie))\n",
    "print(\" ===> 추천된 영화:\")  # movie 값 출력\n",
    "print(movie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16718b76-f59d-48f7-906f-5d2371417803",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "16718b76-f59d-48f7-906f-5d2371417803",
    "outputId": "6e3371cd-d294-4be7-a868-2eae5ee6e5de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first={\n",
      "  movie: ChatPromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, template='{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.'), additional_kwargs={})])\n",
      "         | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000014F43D570B0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000014F43D54B90>, root_client=<openai.OpenAI object at 0x0000014F43D54920>, root_async_client=<openai.AsyncOpenAI object at 0x0000014F433E8080>, model_name='moonshotai/kimi-k2-instruct-0905', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "         | StrOutputParser()\n",
      "} middle=[ChatPromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, template='{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요'), additional_kwargs={})]), ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000014F43D570B0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000014F43D54B90>, root_client=<openai.OpenAI object at 0x0000014F43D54920>, root_async_client=<openai.AsyncOpenAI object at 0x0000014F433E8080>, model_name='moonshotai/kimi-k2-instruct-0905', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n",
      "\n",
      "🔹 영화 줄거리 요약:\n",
      " **버닝**\n",
      "\n",
      "버닝  \n",
      "감독: 이창동  \n",
      "출연: 유아인, 스티븐 연, 전종서  \n",
      "줄거리:  \n",
      "배달 일을 하며 생계를 유지하는 종수는 어릴 때 동네였던 희아가 그의 집 앞을 지나며 우연히 재회한다. 희아는 아프리카로 여행을 떠났다가 돌아오며 만난 신비로운 남자 ‘벤’을 소개한다. 어느 날 희아는 종수에게 “나는 회전율이 없는 사람”이라는 말을 남긴 채 사라지고, 종수는 희아의 실종과 벤의 정체에 대한 의심을 품게 된다. 평범한 일상 속에 감춰진 계급과 욕망, 불안이 서서히 드러나며 종수는 벤을 향해 치달을 수밖에 없게 된다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(chain2)\n",
    "\n",
    "# 실행: \"SF\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\\n\", response) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb684fd",
   "metadata": {},
   "source": [
    "##### chain1과 chain2에서 영화 제목이 일관되게 전달 되도록 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e30883ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 영화 줄거리 요약:\n",
      "('**버닝**\\n'\n",
      " '\\n'\n",
      " '제목: 버닝 (Burning, 2018)  \\n'\n",
      " '감독: 이창동  \\n'\n",
      " '캐스팅: 유아인, 스티븐 연, 송강호  \\n'\n",
      " '줄거리:  \\n'\n",
      " '일상의 굴레에서 벗어나고 싶은 청년 종수는 어릴 적 동네 친구 해미를 만나 그녀의 아프리카 여행 이야기를 듣고, 돌아온 뒤 해미가 소개한 '\n",
      " '신비로운 부잣집 젊은이 벤을 만난다. 어느 날 해미가 사라지고, 종수는 벤을 의심하며 추적하지만, 사건은 점점 더 미궁 속으로 빠져든다.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요.\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 실행: \"Drama\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\")\n",
    "pprint(response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
